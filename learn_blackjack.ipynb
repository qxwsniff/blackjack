{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align=\"center\"> Learning to play Blackjack with Q-learning </div>\n",
    "\n",
    "### <font color=\"red\"> To do: amend comments on success rate now that draws have been removed </font>\n",
    "\n",
    "In this notebook I will show how Q-learning can be used by an agent with no prior knowledge to teach itself to play Blackjack. While I would not expect the agent to find a way to make money from gambling, I am interested in whether artifical intelligence can play Blackjack better than a human after experiencing hundreds of thousands of games. To make the comparison we will simulate games under a strategy recommended by a human expert, and hopefully show that the agent can consistently beat human performance.\n",
    "\n",
    "In terms of coding strategy, I start with low level functions that are incorporated into increasingly large functions. This helps us reduce duplication of code when we vary the parameters under which agents are trained.\n",
    "\n",
    "\n",
    "#### Special thanks:\n",
    "My implementation relies heavily on the following key sources, which I highly recommend:\n",
    " - <a href=\"https://github.com/openai/gym/blob/master/gym/envs/toy_text/blackjack.py\" target=\"_blank\" >Blackjack environment created by OpenAI Gym</a>\n",
    " - <a href=\"https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0\" target=\"_blank\" >Arthur Juliani's Medium tutorial on Q-learning implementation</a>\n",
    " -  <a href=\"https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-7-action-selection-strategies-for-exploration-d3a97b7cceaf\" target=\"_blank\" >Arthur Juliani's Medium tutorial on policy rule implementation</a>\n",
    "\n",
    "\n",
    "#### Contents:\n",
    "1. Create Blackjack environment \n",
    "2. Q-learning implementation and variations\n",
    "3. Connect Q-learning algorithm with environment\n",
    "4. Training example\n",
    "5. Optimization: training with grid search\n",
    "6. Comparison against human strategy\n",
    "7. Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0) Load modules & basic set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "from gym.utils import seeding\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import datetime\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Create Blackjack environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basics of the environment are handled in local files *blackjack_env.py* and *settings.py*. The former file is the main environment as coded by <a href=\"https://github.com/openai/gym/blob/master/gym/envs/toy_text/blackjack.py\" target=\"_blank\" >OpenAI Gym</a>, plus some minor modifications I added to make the game more interesting such as the inclusion of the \"Double\" action. The latter file contains some parameters I added which influence the laws of the game held in the main environment file, e.g. controlling when the dealer stops taking cards or how many different actions we allow our agent to perform.\n",
    "\n",
    "For those unfamiliar with Blackjack, I will include the description of the game written by OpenAI Gym. I should emphasise that this is a slightly different version to the standard game, since the action \"split\" is removed to keep things a little simpler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h4> Blackjack rules: </h4>\n",
    "<p>\n",
    "“Blackjack is a card game where the goal is to obtain cards that sum to as near as possible to 21 without going over.  They're playing against a fixed dealer. Face cards (Jack, Queen, King) have point value 10. Aces can either count as 11 or 1, and it's called 'usable' at 11. This game is placed with an infinite deck (or with replacement).\n",
    "The game starts with each (player and dealer) having one face up and one face down card. The player can request additional cards (hit=1) until they decide to stop (stick=0) or exceed 21 (bust). After the player sticks, the dealer reveals their facedown card, and draws until their sum is 17 or greater.  If the dealer goes bust the player wins. If neither player nor dealer busts, the outcome (win, lose, draw) is decided by whose sum is closer to 21.  The reward for winning is +1, drawing is 0, and losing is -1.” – <i>OpenAI Gym source code</i> </p>\n",
    "<p>\n",
    "    \n",
    "<b>NB:</b> The above variant of Blackjack excludes the actions ‘Double’ and ‘Split’, though we reinstate 'Double' to study agents’ approach to risk-taking. We leave out the latter for simplicity reasons.\n",
    "</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load settings of environment from local file\n",
    "from settings import *\n",
    "\n",
    "# load the Blackjack environment from local file\n",
    "from blackjack_env import *\n",
    "\n",
    "# create environment\n",
    "env = BlackjackEnv()\n",
    "\n",
    "# Confirm the environment our agent will play in\n",
    "ENV_VALS = (BLACKJACK_SCORE, DEALER_STOP, DOUBLE_BIAS, ODDS_BOOST, NUM_ACTIONS)\n",
    "print(\"Created environment:\")\n",
    "print(\"Goal: %i | DealerStop: %i | DoubleBias: %i | DoubleBoost: %i | NumActions: %i\" % ENV_VALS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is always useful to articulate the environment's state transition matrix before training. This helps us understand the environment our agent needs to traverse in a more mathematical fashion, particularly the probabilities associated with drawing cards randomly. But to keep this notebook focussed on Q-learning itself, I have included that analysis in a <a href=\"https://github.com/slmwest/blackjack/blob/master/state_transition_analysis.ipynb\" target=\"_blank\">separate notebook here</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Q-learning implementation and variations\n",
    "\n",
    "We will start by implementing a series of selection policies, all of which control how our agent chooses actions. Since the agent will start with a blank canvas, we cannot simply let the agent always pick the \"best\" action. Rather, these policies help the agent manage the \"exploration-exploitation trade-off\". In all cases, the agent will start by prioritising \"exploration\": choosing actions mostly randomly so that it can experience as many different rewards and penalties as possible. As it gains more experience, it will begin to reduce the frequency of these random actions, instead prioritising \"exploitation\": using its experience so far to choose the action with highest expected future rewards.\n",
    "\n",
    "The policies implemented are:\n",
    "- e-greedy policy\n",
    "- boltzmann policy\n",
    "- both of the above but with Double-Q learning (see more in the following block of code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_egreedy(Q_row, number_actions, eps=0.9):\n",
    "    \"\"\"\n",
    "    Select an action (index) based on e-greedy policy,\n",
    "    e.g. random with probability e and per\n",
    "    current Q-values with probability 1-e\n",
    "    \"\"\"\n",
    "    if np.random.rand() < eps:\n",
    "        # pick by random choice\n",
    "        return np.random.choice(np.arange(0, number_actions))   \n",
    "    else:\n",
    "        # choose highest expected value action\n",
    "        return np.argmax(Q_row)    \n",
    "\n",
    "def select_boltzmann(Q_row, number_actions, tau=1):\n",
    "    \"\"\"\n",
    "    Select an action (index) based on current Q values and\n",
    "    the current state of annealing, e.g. using inverse\n",
    "    temperature, tau.\n",
    "    \n",
    "    PARAMS:\n",
    "    tau = inverse temperature, e.g. as tau approaches 0\n",
    "          boltzmann distribution approaches uniform sampling.\n",
    "          higher tau prefers actions with higher expected values\n",
    "    \"\"\"\n",
    "    # normalize wrt minimum values, ensuring no negatives\n",
    "    Q_row_ajd = Q_row - Q_row.min()\n",
    "\n",
    "    # calculate probabilities under boltzmann distribution\n",
    "    Q_pr = np.exp(tau * Q_row_ajd) / np.exp(tau * Q_row_ajd).sum()\n",
    "    \n",
    "    # Make selection based on probabilities\n",
    "    try:\n",
    "        action_value = np.random.choice(Q_pr, p=Q_pr)\n",
    "    except:\n",
    "        # we might exceed memory limits for very large numbers\n",
    "        # when the temperature is very low. In these cases\n",
    "        # we would do well to simply pick the max value again\n",
    "        action_value = np.argmax(Q_row)\n",
    "    return np.argmax(Q_pr == action_value)\n",
    "\n",
    "def select_a(Q_row, policy=\"e\", param=0.9):\n",
    "    \"\"\" Select action from a row of Q for the given state\n",
    "    and for a given policy & parameter\n",
    "    \n",
    "    if policy == \"e\" then we will use e-greedy policy\n",
    "    if policy == \"b\" then we will use boltzmann distribution\n",
    "    \"\"\"\n",
    "    # choose action based on policy required\n",
    "    if policy==\"e\":\n",
    "        # use e-greedy policy, where param = epsilon\n",
    "        return select_egreedy(Q_row, env.action_space.n, param)\n",
    "    else:\n",
    "        # use boltzmann policy, where param = tau = inverse temperature\n",
    "        return select_boltzmann(Q_row, env.action_space.n, param)\n",
    "    \n",
    "def doubleQ_select(Q_a, Q_b, s, policy=\"e\", policy_param = 0.9):\n",
    "    \"\"\"\n",
    "    Function which enables selection using two Q matrices. Per van Hasselt's\n",
    "    original implementation:\n",
    "       'In our experiments, we calculated the average of the two Q values for each\n",
    "    action and then performed e-greedy exploration with the resulting average\n",
    "    Q values.' (Hado van Hasselt)\n",
    "    \n",
    "    Optional params:\n",
    "        policy = \"e\" or \"b\" for e-greedy and boltzmann respectively\n",
    "        policy_param = float, epsilon if e-greedy or inverse temperature (tau)\n",
    "                       if boltzmann \n",
    "    \"\"\"\n",
    "    \n",
    "    # take average Q values under consideration for given state\n",
    "    Q_avg_row =  (Q_a[s] + Q_b[s])/2\n",
    "    \n",
    "    # choose action based on given policy and policy parameter\n",
    "    return select_a(Q_avg_row, policy, policy_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now move to defining our update rules, which is how the agent learns from experience in playing Blackjack. We will use the standard update rule as well as a variation called **Double Q learning**, where two matrixes are maintained to avoid over-estimation of expected returns. For more information on this variation see https://arxiv.org/abs/1509.06461 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vanillaQ_update(Q, r, s, s1, a, lr, y):\n",
    "    \"\"\"\n",
    "    Update Q-matrix using standard update rule\n",
    "    \"\"\"\n",
    "    Q[s][a] = Q[s][a] + lr*(r + y*np.max(Q[s1]) - Q[s][a])\n",
    "    return Q\n",
    "\n",
    "def doubleQ_update(Q_a, Q_b, r, s0, s1, a,\n",
    "                   lr, y, prob_update_Q_a = 0.5):\n",
    "    \"\"\"\n",
    "    Randomly select a Q matrix to update, estimating future\n",
    "    rewards from the other matrix. Per van Hasselt's original\n",
    "    implementation.\n",
    "    \n",
    "    Parameters:\n",
    "        - prob_update_Q_a: probability of updating the first matrix.\n",
    "                           (allows experimentation with reliance on\n",
    "                           the first Q matrix vs the second Q matrix)\n",
    "    \"\"\"\n",
    "    \n",
    "    if np.random.rand() < prob_update_Q_a:\n",
    "        # update Q_a matrix, taking copy before update for reference\n",
    "        Q_old = np.copy(Q_a)\n",
    "        optimal_a = np.argmax(Q_a[s1][a])\n",
    "        Q_a[s0][a] = Q_a[s0][a] + lr*(r + y*Q_b[s1][optimal_a] - Q_a[s0][a])\n",
    "        \n",
    "    else:\n",
    "        # update Q_b matrix, taking copy before update for reference\n",
    "        Q_old = np.copy(Q_b)\n",
    "        optimal_b = np.argmax(Q_b[s1][a])\n",
    "        Q_b[s0][a] = Q_b[s0][a] + lr*(r + y*Q_a[s1][optimal_b] - Q_b[s0][a])\n",
    "        \n",
    "    return Q_a, Q_b, Q_old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Connect Q-learning algorithm with environment\n",
    "\n",
    "Now that we have an environment and functions that implement Q-learning, we can connect them together and watch our agent learn to play! We will put this functionality into a function so that we can easily recall it under different parameters in the rest of this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def playGame(Q_a=None, Q_b = None, verbose=0,\n",
    "             dbl_Q=0, lr=0.1, y=0.6,\n",
    "             policy = \"e\", policy_param=0.7,\n",
    "             num_episodes = 1, cb_over_num_eps=10000):\n",
    "    \"\"\"\n",
    "    Main function where agent learns to play Blackjack.\n",
    "    \n",
    "    Inputs:\n",
    "      Q_a, Q_b        = None, None or pre-trained matrix, None\n",
    "      verbose         = verbosity level\n",
    "      dbl_Q           = 1 if using double Q learning\n",
    "      policy          = \"e\" for e-greedy, \"b\" for boltzmann\n",
    "      policy_param    = float controlling above policy\n",
    "      num_episodes    = number of games to play\n",
    "      cb_over_num_eps = maintain a callback version of agent \n",
    "                        if they have superior performance over\n",
    "                        this number of games\n",
    "                        \n",
    "    Outputs:\n",
    "      Q_out           = Q-matrix of agent after final episode\n",
    "      rList           = list of agent's rewards in each episode \n",
    "      Q_cb            = Q-matrix of callback agent\n",
    "      last_cb_ep      = episode number where callback agent was created\n",
    "    \"\"\"\n",
    "    \n",
    "    # state space needs to be blackjack_score+11\n",
    "    # e.g. ace on top of a score of 21\n",
    "    if Q_a is None:\n",
    "        Q_a = np.zeros([BLACKJACK_SCORE+11,11,2,env.action_space.n])\n",
    "\n",
    "    # take a copy of Q matrix if we are using double Q learning\n",
    "    if dbl_Q != 0:\n",
    "        Q_b = np.copy(Q_a)\n",
    "    \n",
    "    # prepare a 'call-back' version of the Q-matrix\n",
    "    # e.g. the one with best mean rewards over last N episodes\n",
    "    Q_cb = Q_a.copy()\n",
    "    best_meanR = -999999    # value holding \"best score\" yet\n",
    "    last_cb_ep = 0          # record of last episode the call-back is made to\n",
    "    a_freq = np.zeros(env.action_space.n)\n",
    "\n",
    "    # if using Boltzmann policy, set rate of annealing (tau = inverse temperature)\n",
    "    # grows from start value to 200 over (pc_episodes_tau_growth*num_episodes) steps \n",
    "    if policy==\"b\":\n",
    "        pc_episodes_tau_growth = 0.6\n",
    "        end_growth_ep = pc_episodes_tau_growth*num_episodes\n",
    "        tau_growth = (200/policy_param)**(1/end_growth_ep)\n",
    "\n",
    "    #create lists to contain total rewards and steps per episode\n",
    "    rList = []\n",
    "    for i in range(num_episodes):\n",
    "        #Reset environment and get first new observation\n",
    "        s = env.reset()\n",
    "        rAll = 0\n",
    "        d = False\n",
    "        j = 0\n",
    "        \n",
    "        # game will not exceed 20 moves, limit while loop out of caution\n",
    "        while j < 20:\n",
    "            j+=1\n",
    "\n",
    "            # choose an acion per given policy        \n",
    "            if dbl_Q==0:\n",
    "                Q_row = Q_a[s]\n",
    "                a = select_a(Q_row, policy, policy_param)  \n",
    "            else:\n",
    "                Q_avg_row =  (Q_a[s] + Q_b[s])/2\n",
    "                a = select_a(Q_avg_row, policy, policy_param) \n",
    "\n",
    "            #Get new state and reward from environment\n",
    "            Q_old = np.copy(Q_a)\n",
    "            player_hand_old = env.player.copy()\n",
    "            s1,r,d,_ = env.step(a)\n",
    "            \n",
    "            # Update Q-Table with new knowledge, unless in testing mode (lrate = 0.0)\n",
    "            if lr > 0:\n",
    "                if dbl_Q==0:\n",
    "                    Q_a[s][a] = Q_a[s][a] + lr*(r + y*np.max(Q_a[s1]) - Q_a[s][a])\n",
    "                else:\n",
    "                    # Double-Q learning: use the second matrix as estimate of expected returns\n",
    "                    Q_a, Q_b, Q_old = doubleQ_update(Q_a, Q_b, r, s, s1, a, lr, y)\n",
    "    \n",
    "            # inspect the step & Q matrix once, at 1/5 through training\n",
    "            if (i == num_episodes//5) & (verbose > 2):\n",
    "                if ((dbl_Q==0)|(np.array_equal(Q_b, Q_old))):\n",
    "                    Q_new = np.copy(Q_a)\n",
    "                else:\n",
    "                    Q_new = np.copy(Q_b) \n",
    "                show_step(player_hand_old, env.player, env.dealer,\n",
    "                          s, s1, a, Q_old, Q_new, r, d)\n",
    "            \n",
    "            # update rewards and state\n",
    "            rAll += r\n",
    "            s = s1\n",
    "\n",
    "            if d == True:            \n",
    "                #Reduce chance of random action as we train the model.\n",
    "                # for e-greedy policy, reduce epsilon\n",
    "                if policy==\"e\":\n",
    "                    if policy_param >= 0.5:\n",
    "                        policy_param *= 0.99999\n",
    "                    else:\n",
    "                        policy_param *= 0.9999\n",
    "                        \n",
    "                # for boltzmann policy, increase tau (inverse temperature)\n",
    "                if ((policy==\"b\") & (i < end_growth_ep)):\n",
    "                    policy_param *= tau_growth\n",
    "                \n",
    "                # For each of the final 5 episodes, show the game for inspection\n",
    "                if (i >= (num_episodes-5)) & (verbose > 1):\n",
    "                    show_ep(env.player, env.dealer, r, i)\n",
    "                \n",
    "                break\n",
    "\n",
    "        # append reward to list\n",
    "        rList.append(rAll)\n",
    "        \n",
    "        # update the callback Q-matrix IIF better average over last N episodes\n",
    "        meanR_lastN_eps = meanR_lastN(rList, n=cb_over_num_eps)\n",
    "        if ((i > cb_over_num_eps) & (meanR_lastN_eps > best_meanR)):\n",
    "            \n",
    "            # take average of Q-values first if double Q learning\n",
    "            if dbl_Q == 0:\n",
    "                Q_cb = np.copy(Q_a)\n",
    "            else:\n",
    "                Q_cb = (Q_a + Q_b) / 2\n",
    "            last_cb_ep = i\n",
    "            best_meanR = meanR_lastN_eps\n",
    "            \n",
    "        # show some training feedback every n episodes\n",
    "        feedback_freq = num_episodes//5\n",
    "        if verbose > 0:\n",
    "            if i % feedback_freq == 0:\n",
    "                print(\"Ep: {}\\tMean reward over last {} episodes: {}. ({}-policy @ {})\".format(i,\n",
    "                        cb_over_num_eps, meanR_lastN_eps,\n",
    "                        policy, np.around(policy_param, decimals=5)))\n",
    "        \n",
    "    # show overall success history of agent \n",
    "    if verbose > 1:\n",
    "        plt.figure(figsize=(12,4))\n",
    "        plt.plot(np.cumsum(rList))\n",
    "        plt.title('Performance vs. episodes')\n",
    "        plt.ylabel('Total Returns')\n",
    "        plt.xlabel('Episode number')\n",
    "        plt.axvline(x=last_cb_ep, linestyle=\"--\", color=\"black\")    # show the last callback episode\n",
    "        plt.show()\n",
    "        \n",
    "    # before returning Q matrix, take average if double Q-learning\n",
    "    if dbl_Q == 0:\n",
    "        Q_out = np.copy(Q_a)\n",
    "    else:\n",
    "        Q_out = (Q_a + Q_b)/2\n",
    "        \n",
    "    return Q_out, rList, Q_cb, last_cb_ep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Training example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start training, we want to have some functions that let us evaluate the agent's performance numerically, as well as some ability to visually inspect what is going on at both a high- and granular-level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode(l):\n",
    "    \"\"\" Find the mode of a given list l. \"\"\"\n",
    "    return max(set(l), key=l.count)\n",
    "\n",
    "def meanR_lastN(r_list, n=200):\n",
    "    \"\"\" Find mean over the last n items in a list \"\"\"\n",
    "    return np.mean(r_list[-n:])\n",
    "\n",
    "def calc_success_rate(rList, eval_last_n=50000, produce_ts=False, title_add=\" (final agent)\"):\n",
    "    \"\"\" Calcuate success rate over moving window using a given rList\n",
    "        (This is more easy to understand in context of Blackjack)\"\"\"\n",
    "    # convert to binary 1/0 for success/failure\n",
    "    r_01 = [1*(r>0) for r in rList]\n",
    "    ts_success = []\n",
    "    \n",
    "    # calculate average success rate for evaluation period\n",
    "    num_wins = np.sum(r_01)\n",
    "    num_losses = np.sum([1*(r<0) for r in rList])\n",
    "    mean_success_rate = num_wins / (num_wins + num_losses)\n",
    "    \n",
    "    if produce_ts:\n",
    "        # calculate success rate over moving window\n",
    "        window=eval_last_n #//200\n",
    "        ts_step=1#ts_step = np.max([window//10, 1]) # must be positive step \n",
    "        for i in np.arange(window, len(rList), ts_step):\n",
    "            num_wins = np.sum(r_01[i-window:i])\n",
    "            num_losses = np.sum([1*(r<0) for r in rList[i-window:i]])\n",
    "            success_in_window = num_wins / (num_wins + num_losses)\n",
    "            ts_success.append(success_in_window)\n",
    "            \n",
    "        # plot success over time, plus mean success rate in eval period\n",
    "        plt.figure()\n",
    "        plt.suptitle(\"Success rate over time{}\".format(title_add))\n",
    "        plt.title(\"Mean success rate during evaluation: %.3f\" % mean_success_rate)\n",
    "        plt.plot(ts_success)\n",
    "        plt.ylim([0.0,1.0])\n",
    "        plt.ylabel(\"Success rate\")\n",
    "        plt.xlabel(\"Number of episodes after initial evaluation @ Ep. {}\".format(window))\n",
    "        plt.show()\n",
    "\n",
    "    return ts_success, mean_success_rate\n",
    "    \n",
    "\n",
    "def action_dict(a, short=False):\n",
    "    if short:\n",
    "        lookup = {0: \"St\", 1: \"Hi\", 2: \"Db\", 3: \"Su\", 4: \"In\"}\n",
    "    else:\n",
    "        lookup = {0: \"Stick\", 1: \"Hit\", 2: \"Double\", 3: \"Surrender\", 4: \"Invest\"}\n",
    "    return lookup[a]\n",
    "\n",
    "def convert_first_1_to_11(l):\n",
    "    \"\"\" Convert the first 1 in a hand to 11, e.g. to faciliate understanding of hands played involving an Ace \"\"\"\n",
    "    for idx, i in enumerate(l):\n",
    "        if i == 1:\n",
    "            l[idx] = 11\n",
    "            break\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_ep(player_hand, dealer_hand, reward, ep_no, cumulative=True):\n",
    "    \"\"\" Summarise the episode in text once it is complete \"\"\"\n",
    "    \n",
    "    # set some placeholder strings to indicate who won/lost/drew\n",
    "    pl_bust = \"\"\n",
    "    dl_bust = \"\"\n",
    "    \n",
    "    # show if anyone went bust with XXX\n",
    "    if is_bust(player_hand):\n",
    "        pl_bust = \"XXX\"\n",
    "    if is_bust(dealer_hand):\n",
    "        dl_bust = \"XXX\"\n",
    "    \n",
    "    # show who won, using !!! for win and --- for draw\n",
    "    if reward > 0:\n",
    "        pl_win = \"!!!\"\n",
    "        dl_win = \"\"\n",
    "    elif reward < 0:\n",
    "        pl_win = \"\"\n",
    "        dl_win = \"!!!\"\n",
    "    else:\n",
    "        pl_win = \"---\"\n",
    "        dl_win = \"---\"\n",
    "        \n",
    "    # update hands to show effects of an Ace being used as 11 (instead of 1)\n",
    "    if usable_ace(player_hand):\n",
    "        player_hand = convert_first_1_to_11(player_hand)\n",
    "    if usable_ace(dealer_hand):\n",
    "        dealer_hand = convert_first_1_to_11(dealer_hand)\n",
    "        \n",
    "    # display results\n",
    "    print(\"--- SUMMARY OF EP #{} ---\".format(ep_no))\n",
    "    if cumulative:\n",
    "        # simplest view\n",
    "        print(\"Player:\\t{} {}{}\".format(np.cumsum(player_hand), pl_bust, pl_win))\n",
    "        print(\"Dealer:\\t{} {}{}\".format(np.cumsum(dealer_hand), dl_bust, dl_win))\n",
    "        print(player_hand)\n",
    "        print(dealer_hand)\n",
    "    else:\n",
    "        # more detailed view, showing progression of cards from initial (visible) hands to final hands\n",
    "        print(\"Player:\\t{} >> {} >> {} {}{}\".format(player_hand[:2], player_hand, sum_hand(player_hand),\n",
    "                                                    pl_bust, pl_win))\n",
    "        print(\"Dealer:\\t{} >> {} >> {} {}{}\".format(dealer_hand[:1], dealer_hand, sum_hand(dealer_hand),\n",
    "                                                    dl_bust, dl_win))\n",
    "\n",
    "def show_step(player_hand_old, player_hand_new, dealer_hand,\n",
    "              s0, s1, a, Q0, Q1, r, d):\n",
    "    \"\"\" Give a detailed view of each step in a hand \"\"\"\n",
    "    # current state summary and action\n",
    "    print(\"\"\"-----------------------\n",
    "Player's old hand:\\t{} (={})\n",
    "Dealer's face-up card:\\t{}\n",
    "Player had useable:\\t{}\n",
    "Player action:\\t\\t{} ({})\"\"\".format(player_hand_old, s0[0], s0[1], s0[2], a, action_dict(a)))\n",
    "    \n",
    "    # effects of action\n",
    "    if player_hand_old != player_hand_new:\n",
    "        print(\"\"\"Player got card:\\t{}\"\"\".format(player_hand_new[-1]))\n",
    "        \n",
    "    # Dealer's eventual outcome\n",
    "    print(\"Dealer's hand:\\t{} (={})\".format(dealer_hand, sum_hand(dealer_hand)))\n",
    "    print(\"{}\\n{}\".format(s0, s1))\n",
    "    \n",
    "    print(\"r:{} | Done: {}\".format(r, d))\n",
    "    \n",
    "    # show two Q matrices separately\n",
    "    inspect_Q(Q0)\n",
    "    inspect_Q(Q1)\n",
    "    \n",
    "    # show the difference\n",
    "    Q_diff = Q1 - Q0\n",
    "    inspect_Q(Q_diff)\n",
    "\n",
    "def inspect_Q(Q_in):\n",
    "    \"\"\" Inspect the Q matrix as heatmaps\n",
    "    Split out each action's Q-values for all possible states\"\"\"\n",
    "        \n",
    "    # Heatmaps: Show side-by-side action Q-matrix, with two rows for each Usable Ace state\n",
    "    color_limits = np.max([abs(np.min(Q_in)), np.max(Q_in)])\n",
    "    i_labels = ['No useable ace', 'Useable ace']\n",
    "    j_labels = ['Stick', 'Hit', 'Double', 'Surrender', 'Invest'][:NUM_ACTIONS]\n",
    "    \n",
    "    # new row of plots for each of the binary states Ace / no Ace\n",
    "    for i in np.arange(0, len(i_labels)):    \n",
    "        plt.figure()\n",
    "        f, axes = plt.subplots(1,len(j_labels), sharex=False, sharey=False,\n",
    "                                          figsize=(12,6))\n",
    "        plt.title(i_labels[i])\n",
    "        # show Q values for each possible action, across all hand values x initial dealer card\n",
    "        for j in np.arange(0, len(j_labels)):\n",
    "            # show each heat map, adding color bar for the last plot only\n",
    "            showCbar = j == len(j_labels)-1\n",
    "            # obtain the relevant Q values - hiding non-used states (4- & 22+ for player / 0 for dealer)\n",
    "            g = sns.heatmap(Q_in[4:22,1:,i,j], cmap='seismic_r', cbar=showCbar,\n",
    "                            vmin = -color_limits, vmax = color_limits, center=0, ax=axes[j])\n",
    "            g.set_title(\"{}\\n - {} - \".format(j_labels[j], i_labels[i]))\n",
    "            g.set_xlabel('Dealer initial card')\n",
    "            # set agent hand value range of 4-21 inclusive, dealer 2-11 inclusive\n",
    "            g.set_yticklabels(np.arange(4,22), rotation=0)\n",
    "            g.set_xticklabels(np.arange(1,11), rotation=0)  # where Ace = 1 for now\n",
    "            # only show y label on first plot\n",
    "            if j == 0:\n",
    "                g.set_ylabel('Agent hand value')\n",
    "                \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are almost ready to start training. All we have to do first is choose how long we want to train the agent for, how many games we are going to evaluate it over, and of course some hyper-parameter values. We will start with some parameter values which seem sensible, and move onto more robust experimentation in the following section. For this reason we will keep the number of training episodes and evaluation window fairly low for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set scope of training and evaluation\n",
    "# number of episodes to train agent over\n",
    "NUM_EPISODES_TRAIN = 15000           \n",
    "\n",
    "# evaluate agent with mean rewards over last (N) episodes\n",
    "EVAL_LAST_N_EPS = 2500                 \n",
    "\n",
    "### Set verbosity level\n",
    "# 0: nothing\n",
    "# 1: validation metrics only\n",
    "# 2: validation, perf-vs-episodes, last 5 games\n",
    "# 3: inspect Q-matrix update 1/5 of way into training\n",
    "VERBOSE =2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyper-parameters: grid format will be beneficial when we optimize these \n",
    "grid = ParameterGrid({\"dbl_Q\" : [0],                # 1 to use Double Q learning\n",
    "                          \"lr\": [0.01],             # learning rate\n",
    "                          \"y\": [0.4],               # gamma\n",
    "                          \"policy\": \"b\",            # \"e\" for e-greedy, \"b\" for boltzmann\n",
    "                          \"policy_param\":  [1],     # epsilon / tau (inverse temperature)\n",
    "                          \"num_episodes\": [NUM_EPISODES_TRAIN],\n",
    "                          \"cb_over_num_eps\": [EVAL_LAST_N_EPS],\n",
    "                          \"verbose\": [VERBOSE]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can start training an agent in the next block, wrapping the learning process, evaluation & record management into a function we can call again later. This should complete in less than 5 seconds - quite impressive for 15000 games!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_agent(p_idx, params, exportMe=True, eval_metrics=[]):\n",
    "    # confirm parameters used for training\n",
    "    agent_summary = (params['dbl_Q'], params['lr'], params['y'],\n",
    "                     params['policy'], params['policy_param'])\n",
    "    print(\"---------------------------\\nNow training agent {}/{}\".format(p_idx+1, grid_size))\n",
    "    print(\"DblQ: %.2f | LR: %.3f | g: %.3f | pol: %s | pol_param: %.5f\" % agent_summary)\n",
    "    \n",
    "    # train agent using current parameters\n",
    "    start_time = time.time()\n",
    "    Q, rList, Q_CB, lastCB_ep = playGame(Q_a=None, Q_b=None, **params)\n",
    "    end_time = time.time()\n",
    "    time_elapsed = end_time - start_time  # time difference in seconds\n",
    "    games_per_sec = NUM_EPISODES_TRAIN / time_elapsed \n",
    "    print(\"...completed in %.1f seconds @ %.1f games per second\" % (time_elapsed,\n",
    "                                                                    games_per_sec))\n",
    "    \n",
    "    # calculate evaluation metrics\n",
    "    eval_final = meanR_lastN(rList, n=EVAL_LAST_N_EPS)\n",
    "    eval_cb = meanR_lastN(rList[:lastCB_ep], n=EVAL_LAST_N_EPS)\n",
    "    \n",
    "    # calculate the success rate metrics\n",
    "    show_success_ts_plot = VERBOSE > 1\n",
    "    ts_success_final, eval_final_success = calc_success_rate(rList, eval_last_n=EVAL_LAST_N_EPS,\n",
    "                                                             produce_ts = show_success_ts_plot,\n",
    "                                                             title_add=\" (final agent)\")\n",
    "    ts_success_cb, eval_cb_success = calc_success_rate(rList[:lastCB_ep], eval_last_n=EVAL_LAST_N_EPS,\n",
    "                                                              produce_ts = show_success_ts_plot,\n",
    "                                                              title_add=\" (CB agent)\")\n",
    "\n",
    "    if VERBOSE>-1:\n",
    "        print(\"---------------------------\\nValidation metrics\\n---------------------------\")\n",
    "        print(\"After final episode, mean reward of {} over last {} episodes --> success rate: {}\".format(eval_final, EVAL_LAST_N_EPS, eval_final_success))\n",
    "        print(\"After episode {}, mean reward of {} over last {} episodes --> success rate: {}\".format(lastCB_ep, eval_cb, EVAL_LAST_N_EPS, eval_cb_success))\n",
    "    # Pickle Q matrices for later use\n",
    "    if exportMe:\n",
    "        print(\"---------------------------\\nPickling agents\")\n",
    "        export_name = 'Qmatrix_expID_{}_Fi_DblQ{}_lr{}_g{}_pol{}_polparam{}.p'.format(p_idx, params['dbl_Q'], params['lr'],\n",
    "                                                                    params['y'], params['policy'], params['policy_param'])\n",
    "        name_fi = Q_DATA_DIR + export_name\n",
    "        pickle.dump(Q , open(name_fi, \"wb\" ) )\n",
    "\n",
    "        # Pickle the call back too, referencing the call-back episode in filename\n",
    "        export_name_cb = 'Qmatrix_expID_{}_CB{}_DblQ{}_lr{}_g{}_pol{}_polparam{}.p'.format(p_idx, lastCB_ep,\n",
    "                                                                                  params['dbl_Q'], params['lr'],\n",
    "                                                                                  params['y'], params['policy'], params['policy_param'])\n",
    "        name_cb = Q_DATA_DIR + export_name_cb \n",
    "        pickle.dump(Q_CB, open(name_cb, \"wb\" ) )\n",
    "\n",
    "        # pickle the rLists using for later analysis (same filenames but different folder)\n",
    "        pickle.dump(rList , open(RLIST_DATA_DIR + export_name, \"wb\" ) )\n",
    "        pickle.dump(rList[:lastCB_ep], open(RLIST_DATA_DIR + export_name_cb, \"wb\" ) )\n",
    "\n",
    "        # form Vector of validation metrics, for both final agent and call-back agent\n",
    "        eval_vec_fi = [name_fi, params['dbl_Q'], params['lr'], params['y'],\n",
    "                       params['policy'], params['policy_param'],\n",
    "                       params['num_episodes'], params['cb_over_num_eps'],\n",
    "                       0, eval_final, eval_final_success]\n",
    "        eval_vec_cb = [name_cb, params['dbl_Q'], params['lr'], params['y'],\n",
    "                       params['policy'], params['policy_param'],\n",
    "                       params['num_episodes'], params['cb_over_num_eps'],\n",
    "                       lastCB_ep, eval_cb, eval_cb_success]\n",
    "        eval_metrics.append(eval_vec_fi)\n",
    "        eval_metrics.append(eval_vec_cb)\n",
    "        \n",
    "        return eval_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Now training agent 1/1\n",
      "DblQ: 0.00 | LR: 0.010 | g: 0.400 | pol: b | pol_param: 1.00000\n",
      "Ep: 0\tMean reward over last 2500 episodes: -1.0. (b-policy @ 1.00059)\n",
      "Ep: 3000\tMean reward over last 2500 episodes: -0.5036. (b-policy @ 5.85148)\n",
      "Ep: 6000\tMean reward over last 2500 episodes: -0.2284. (b-policy @ 34.21966)\n",
      "Ep: 9000\tMean reward over last 2500 episodes: -0.1304. (b-policy @ 200.0)\n",
      "Ep: 12000\tMean reward over last 2500 episodes: -0.1136. (b-policy @ 200.0)\n",
      "--- SUMMARY OF EP #14995 ---\n",
      "Player:\t[ 3  6 14] \n",
      "Dealer:\t[ 6 16 18] !!!\n",
      "[3, 3, 8]\n",
      "[6, 10, 2]\n",
      "--- SUMMARY OF EP #14996 ---\n",
      "Player:\t[ 9 20] \n",
      "Dealer:\t[ 5 13 21] !!!\n",
      "[9, 11]\n",
      "[5, 8, 8]\n",
      "--- SUMMARY OF EP #14997 ---\n",
      "Player:\t[10 11 15] \n",
      "Dealer:\t[ 9 20] !!!\n",
      "[10, 1, 4]\n",
      "[9, 11]\n",
      "--- SUMMARY OF EP #14998 ---\n",
      "Player:\t[ 3 13 23] XXX\n",
      "Dealer:\t[ 2 13] !!!\n",
      "[3, 10, 10]\n",
      "[2, 11]\n",
      "--- SUMMARY OF EP #14999 ---\n",
      "Player:\t[10 14 16 19] \n",
      "Dealer:\t[10 21] !!!\n",
      "[10, 4, 2, 3]\n",
      "[10, 11]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuYAAAEWCAYAAAAq41LXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xd8FVX6x/HPk4TQixSlG3oTpSuIioKKgL1gl9X9oei6uroWRF1XV0FXV9e+rLqu2LCsnaKoiEoTEARUlBI60kMPKc/vjzvEG0yDlLlJvu/Xa17MnHNm7jMTd/Pck3POmLsjIiIiIiLhigs7ABERERERUWIuIiIiIhITlJiLiIiIiMQAJeYiIiIiIjFAibmIiIiISAxQYi4iIiIiEgOUmIuIFBEz+5uZbTSzdWHHUh6ZWVMz22Fm8UV83WQz61eU1xQRyYkScxEpt4KEa3eQzP1iZv8xs2oHea0mwM1Ae3evX7SRSkG4+wp3r+buGWHHIiJyMJSYi0h5d7q7VwO6AN2BOw/0AmaWABwObHL39Qd5voiIlHNKzEVEAHdfDYwHjgAws5pm9ryZrTWz1cEwlfigboiZfW1mj5rZZmAy8AnQMOh9fzFod4aZLTSzrWY22cza7fu8oLf+NjP7DthpZglB2S1m9p2Z7Qw+/zAzG29m281skpkdEnWNN81snZmlmNkUM+sQVfeimT1lZh8F584wsxZR9R3M7BMz2xz8teCOoDzOzG43syVmtsnM3jCz2jk9MzP7wcwGRR0nBEN5uphZJTN7ObjGVjP7xswOK8jPwsyOMbOpwXnzzKxPVN1kMxtpZjOD+35vX3xmlmRmvu+LTvBzWhrc/zIzuyTqHu80s+Vmtt7MXjKzmlGfcVlQt8nMRuwXW67PpzD3LCICSsxFRICsoSgDgG+Dov8C6UBLoDNwCvD7qFOOBpYChwInA6cBa4KhFEPMrDXwGnAjUA8YB3xgZolR17gIGAjUcvf0oOzc4HqtgdOJfFm4A6hL5P+z/xh1/nigVRDDHOCV/W7rIuCvwCHAYuD+4F6rA5OACUDD4B4/Dc75I3AWcEJQtwV4KpfH9lrwGfucCmx09znAFUBNoAlQB7gG2J3LdbKYWSPgI+BvQG3gz8DbZlYvqtnlwJVBfOnA4zlcp2pQfpq7Vwd6AXOD6iHBdiLQHKgGPBmc1x54BrgsuH4doHHUpfN6Pgd1zyIiWdxdmzZt2srlBiQDO4CtwHLgaaAycBiQClSOansR8HmwPwRYsd+1+gCroo7vAt6IOo4DVgN9oj77yhziuSTq+G3gmajj64F3c7mXWoADNYPjF4HnouoHAD9G3cu3uVznB6Bv1HEDIA1IyKFtS2A7UCU4fgW4O9i/EpgKHHmAP5PbgDH7lU0Ergj2JwOjouraA3uBeCApeAYJQNXg53pu9M8xOOdT4Nqo4zb77hG4G3g9qq5qcP1++T2fg71nbdq0adu3qcdcRMq7s9y9lrsf7u7XuvtuIuPFKwBrgyEJW4F/EemZ3mdlPtdtSCTZB8DdM4NzGuVzjV+i9nfncFwNwMzizWxUMKRiG5GkHiI96/tErw6za9+5RHp0l+QS9+HAO1H3/QOQQeTLSjbuvjioP93MqgBnAK8G1WOIJNSvm9kaM3vIzCrk8pn7f/75+z4/iKE3kQR4n+jntpzIzyr6vnH3ncBgIr3Wa4MhPW2D6mw/m2A/IbjHhtHXD66zab/4cns+B3vPIiKAhrKIiORkJZEe87pB0l7L3Wu4e4eoNp7PNdYQSeIAMDMjkhCvPoBr5OVi4EygH5HhE0n7PqoA564EWuRRd1rUfddy90oeGYOfk33DWc4Evg+Sddw9zd3/6u7tiQwjGURkCEpBYhuz3+dXdfdRUW2aRO03JdJjvXH/C7n7RHc/mUhS/yPw76Aq288muEY6kS9Ba6OvH3zhqLNffDk+n0Lcs4gIoMRcROQ33H0t8DHwiJnVCCb8tTCzEw7gMm8AA82sb9BrejORZH9qEYVZPbjeJqAK8MABnPshUN/MbjSzimZW3cyODuqeBe43s8MBzKyemZ2Zx7VeJzL+fhi/9pZjZieaWUeLTJjdRiR5Lsgyhi8T6YE/NfirQCUz62Nm0eO8LzWz9kHSfC/wlu+3RKJFJs2eEYw1TyUyZGlfm9eAP5lZM4ssj/kAMNYj4/zfAgaZWe9gPsC9ZP9dmevzKcQ9i4gASsxFRHJzOZAIfE9kgt9bZB9OkSd3XwRcCjxBpDf3dCJLM+4tovheIjIEY3UQ4/QDiG07kQmmpxMZ7vIzkYmQAP8E3gc+NrPtwXWPzuk6wbXWAtOI9BCPjaqqT+SZbSMy3OMLIkk3ZvasmT2by/VWEul9vwPYQKSH+hay/74aQ2QM/TqgEtknxO4TR+TL0BpgM5HJmtcGdS8E15gCLAP2EBm/j7svBK4j8iVjLZGf/aqo6+b1fHK9ZxGRgjD3wvwlVUREpOSY2WTgZXd/LuxYRESKmnrMRURERERigBJzEREREZEYoKEsIiIiIiIxQD3mIiIiIiIxICHsAMJSt25dT0pKCjsMERGRErVo0SIA2rRpE3IkIuXH7NmzN7p7vfzaldvEPCkpiVmzZoUdhoiISInq06cPAJMnTw41DpHyxMyW599KQ1lERERERGJCue0xFxERKY/uvPPOsEMQkVwoMRcRESlH+vXrF3YIIpILDWUREREpR+bOncvcuXPDDkNEcqAecxERkXLkxhtvBDT5UyQWlZkeczPrb2aLzGyxmd0edjwiIiIiIgeiTCTmZhYPPAWcBrQHLjKz9uFGJSIiIiJScGVlKEsPYLG7LwUws9eBM4HvQ41qP7v2pnPsqM/YsiuNY1vW4eWrjsbMwg5LRERERGJAmegxBxoBK6OOVwVl2ZjZUDObZWazNmzYUGLB7fPtiq1s2ZUGwNeLN9H6zvGk7E4r8ThEREREJPaUlR7znLqd/TcF7qOB0QDdunX7TX1xO7ZlXT68vjeZ7tz8xjx+Xr+Do/76MUc0qsFb1/SiUoX4kg5JRETKmQceeCDsEEQkF2Wlx3wV0CTquDGwJqRY8nREo5oc2bgWn9x0Atf2aQHAgtXbaHvXBP4+8ceQoxMRkbKuV69e9OrVK+wwRCQHZSUx/wZoZWbNzCwRuBB4P+SY8nVr/7bMv+cULj66KQBPfb6EpNs/YsmGHSFHJiIiZdXUqVOZOnVq2GGISA7MvcRHdBQLMxsAPAbEAy+4+/15te/WrZvPmjWrRGIriL3pmZzzzNcsWL2NyhXieWtYTzo0rBl2WCIiUsb06dMH0DrmIiXJzGa7e7f82pWVMea4+zhgXNhxHKzEhDg+vP44pi3ZxEX/ns7Ax78CYP49p1C9UoWQoxMRERGR4lZWhrKUGT1b1OHNa3rS+JDKAHS852P+PWVpyFGJiIiISHFTYh6DuifV5otbTmRIryQA7h/3A+/NXR1uUCIiIiJSrJSYx6j4OOOeMzow+rKuANzw+lx++mV7yFGJiIiISHEpM5M/D1SsTf7My8xlm7ngX9Oyjr+89USa1K4SYkQiIlJazZ07F4BOnTqFHIlI+VHQyZ/qMS8FejSrzdvDemYdH/fQ50xdvDHEiEREpLTq1KmTknKRGKXEvJToenhtkkcN5N4zOwBw8XMzePKzn0OOSkRESptJkyYxadKksMMQkRxoKEsp9NMv2znl0SkAvHfdsRzVpFbIEYmISGmhdcxFSp6GspRhrQ+rzvx7TqFutYpc8twMFq5JCTskERERESkkJealVPVKFXjy4s5kujPw8a846ZHJpGdkhh2WiIiIiBwkJeal2DHN6/D2sF4ALN2wk5YjxrN+256QoxIRERGRg6HEvJRr16AGyaMGcmanhgD0eOBT1qbsDjkqERERETlQCWEHIEXjnxd2pmGtyjwzeQk9R35G/w71eeSCo6haUT9iERH51b/+9a+wQxCRXKjHvAy5rX9b7h7UHoAJC9fR4S8TGT1lSchRiYhILGnTpg1t2rQJOwwRyYES8zLmyt7NWPS3/gzs2ACAB8b9yMMTF7FgdQp70jJCjk5ERML2wQcf8MEHH4QdhojkQOuYl2FLN+zgpEe+yFb26c0n0KJetZAiEhGRsGkdc5GSp3XMheb1qjH7zn7UrVYxq6zvI18wY+mmEKMSERERkZwoMS/j6lSryKw7+5E8aiB/6tcagMGjp/O7/8wMOTIRERERiabEvBy5oV8rnrs88leUzxdtYODjX5KmlxKJiIiIxAQl5uVMv/aHMffukwFYuGYbXe79hE07UkOOSkRERERiLjE3s3vMbLWZzQ22AVF1w81ssZktMrNTo8q7mtn8oO5xM7Nwoi8dalVJZNnIAVzUoynbU9Pp+rdJJN3+kd4aKiJSDowZM4YxY8aEHYaI5CDmEvPAo+7eKdjGAZhZe+BCoAPQH3jazOKD9s8AQ4FWwdY/hJhLFTNj5Dkdufr45lllPR74lJWbd4UYlYiIFLcmTZrQpEmTsMMQkRzEamKekzOB19091d2XAYuBHmbWAKjh7tM8svbjS8BZYQZamgwf0I7kUQP56xkdADjuoc/58ucNIUclIiLFZezYsYwdOzbsMEQkB7H6vvY/mNnlwCzgZnffAjQCpke1WRWUpQX7+5fLAbiiVxI/rtvOazNXcNnzv67Y8tEfe9O+QQ00OkhEpGx45plnABg8eHDIkYjI/kLpMTezSWa2IIftTCLDUloAnYC1wCP7TsvhUp5HeU6fO9TMZpnZrA0b1Cu8v5HndOTjPx2frWzg41/RbPg4TRAVERERKWahJObu3s/dj8hhe8/df3H3DHfPBP4N9AhOWwVED4prDKwJyhvnUJ7T5452927u3q1evXpFf2NlQOvDqpM8aiCz7uxH/w71s8pvHDuX8vqWWBEREZGSEHNjzIMx4/ucDSwI9t8HLjSzimbWjMgkz5nuvhbYbmbHBKuxXA68V6JBl0F1q1Xk2cu6kjxqIHcObMeXP2+k+/2fsictI+zQRERERMqkmEvMgYeCpQ+/A04E/gTg7guBN4DvgQnAde6+L0scBjxHZELoEmB8iUddhl3Vuxlt61dn445U2t41gb3peimRiIiISFGz8jo8oVu3bj5r1qywwyhVBj7+JQvXbANg2vCTaFCzcsgRiYjIgdq4cSMAdevWDTkSkfLDzGa7e7f82sVij7nEqI/+eBwntT0UgJ4jP2PCgrUs2bAj5KhERORA1K1bV0m5SIxSj7kcsJvemMv/5qzOVvb73s24pX8bKibE53KWiIjEghdffBGAIUOGhBqHSHlS0B5zJeZyUMZMS+au9xb+pvyHe/tTOVHJuYhIrOrTpw8AkydPDjUOkfJEQ1mkWF3WM4nkUQNZNnIAv+/djLhgNfl2d09g445UtuzcG26AIiIiIqWMEnMpFDPjzkHtWTpyINed2AKAbn+bROf7PiHp9o8YM315yBGKiIiIlA5KzKXI3HJqW/54UstsZXe9u4Ck2z8iZVdaSFGJiIiIlA5KzKVI3XRKG5JHDeT7e0/lscGdssrveGd+iFGJiIiIxD5N/pRi5e5c/sJMvvw5sm7upJtOoOWh1UKOSkSk/Nq1axcAVapUCTkSkfJDkz8lJpgZT17cJeu43z++YKnWPhcRCU2VKlWUlIvEKCXmUuxqVq5A8qiBnH5UQwBOeuQLFq3bHnJUIiLl09NPP83TTz8ddhgikgMl5lJinrioM0OPbw7AqY9N4Y1vVoYckYhI+fPGG2/wxhtvhB2GiORAibmUqDsGtMuaFHrr29+RdPtHpGVkhhyViIiISPiUmEuJO6tzIybceFzWcdu7JrAjNT3EiERERETCp8RcQtG2fg2WjRwAQEamc8RfJrJ7b0bIUYmIiIiER4m5hMbMWDZyAE1rR1YHaHf3BCXnIiIiUm4pMZdQmRlf3NKHWlUqAJHk/OdftGKLiEhxmTx5MpMnTw47DBHJgRJzCZ2ZMffuUziva2MAfv/SLPakqedcREREyhcl5hIzHj7/KJ6+pAvLN+1iwONfUl7fSisiUpwefvhhHn744bDDEJEcKDGXmDKgYwOOaV6bpRt20vvBz7WUoohIEfvwww/58MMPww5DRHKgxFxiziu/P4aWh1Zj9dbdtBoxng3bU8MOSURERKTYhZKYm9n5ZrbQzDLNrNt+dcPNbLGZLTKzU6PKu5rZ/KDucTOzoLyimY0NymeYWVLJ3o0Utfg4Y9JNJ9C2fnUAut8/iSUbdoQclYiIiEjxCqvHfAFwDjAlutDM2gMXAh2A/sDTZhYfVD8DDAVaBVv/oPwqYIu7twQeBR4s9uilREy48XgeOvdIAPo+8gWbdqjnXERERMquUBJzd//B3RflUHUm8Lq7p7r7MmAx0MPMGgA13H2aR2YEvgScFXXOf4P9t4C++3rTpfS7oHsT/n155I8qXf82iVdmLA85IhGR0q1y5cpUrlw57DBEJAexNsa8EbAy6nhVUNYo2N+/PNs57p4OpAB1crq4mQ01s1lmNmvDhg1FHLoUl5PbH8bgbk0AGPHOAi5/YaZWbBEROUjjx49n/PjxYYchIjkotsTczCaZ2YIctjPzOi2HMs+jPK9zflvoPtrdu7l7t3r16uV9AxJTHjzvSMZc1QOAKT9toNnwcUxYsC7kqERERESKTrEl5u7ez92PyGF7L4/TVgFNoo4bA2uC8sY5lGc7x8wSgJrA5qK6D4kdx7Wqx9IHBlC7aiIA17w8m5vemBtyVCIipct9993HfffdF3YYIpKDWBvK8j5wYbDSSjMikzxnuvtaYLuZHROMH78ceC/qnCuC/fOAz1zjHMqsuDhjzl0n858h3QH435zV3PD6tyFHJSJSenz66ad8+umnYYchIjkIa7nEs81sFdAT+MjMJgK4+0LgDeB7YAJwnbvvezf7MOA5IhNClwD7Bsg9D9Qxs8XATcDtJXYjEpoT2x7KV7edCMB7c9eQdPtHjJ+/NuSoRERERA6eldfO5W7duvmsWbPCDkMKKWV3Gl3u+4SMzMh/x4O7NWHkOR2Ji9PCPCIiOenTpw8AkydPDjUOkfLEzGa7e7f82sXaUBaRA1KzcgWWPDCAR84/CoCxs1bS/I5xXPzv6SzbuDPk6EREREQKTom5lAnndm3MtOEnZR1PXbKJEx+ezCff/xJiVCIisadOnTrUqZPjqsIiEjINZZEyZ+OOVP43ZxUPjPsRgLFDj+Ho5volJCIiIuHQUBYpt+pWq8jQ41vw5a2RyaGDR09nw/bUkKMSERERyVu+ibmZJZlZYrDf28yuNbMaxR+aSOE0qV2FJy/uDED3+yexa296yBGJiIRv+PDhDB8+POwwRCQHBekxfxdwM2sBvAS0A14t1qhEisigIxtyXKu6ALS/eyL/nPSzes9FpFybNm0a06ZNCzsMEclBQRLzTHdPA84BHnP364FGxRuWSNH57+96ZO0/Ouknut8/SS8lEhERkZiTUIA26WZ2PnAZcFZQVqH4QhIpWnFxRvKogUxcuI6rx8wGIi8lem/uGgD6tTuM567Idz6GiIiISLEqSI/5lcCJwEPuvtTMmgGvFW9YIkXv1A71SR41kJ/+dlq28kk//MIkLasoIiIiIcu3x9zdFwDXRh0vA+4vzqBEilNiQhzJowayeP12dqRmcOlzM/j9S5GlM5+9tAv9j2gQcoQiIsWncePGYYcgIrnIdx1zMzsGuBtIIpLIG+Du3rrYoytGWsdc9pmzYgvnPD01W1mdqolM/NPx1K1WMaSoREREpKwo6DrmBUnMfwBuBWYDGfvK3b1U/+1fiblEW711N58sXMc9H3yfrfzcLo155IKjQopKREREyoKiTMxnuPvRRRZZjFBiLrnZk5bB0DGzmfLThmzlAzs24KlLuoQUlYhI0bjxxhsBeOyxx0KORKT8KGhiXpBVWT4zs5HA/4CsBaDd/btCxCcSsypViOelK3uwZutueo36LKv8o/lr6T1zBRf1aBpidCIihTN37tywQxCRXBQkMe+9378ADhxf9OGIxI6GtSqTPGogb3yzkioV4/nDq98y/H/zWbl5F7ec2gYzCztEERERKUPyTMzNLB74p7u/VULxiMScC7o3AaBZ3aoMfPwrnp68hPmrU3jpyh5KzkVERKTI5LmOubtnADeUUCwiMa1Dw5p8evMJAHz580ZuemNeyBGJiIhIWVKQFwxNNLMbzayBmdXYtxV7ZCIxqEW9avx8f+QFRe98u5pF67aHHJGIyIFp3bo1rVuX6hWPRcqsgqzKsjKHYnf3Uj0DTquySGEs2bCDvo98AcBVvZtx16D2IUckIiIisaqgq7Lk22Pu7k1y2AqVlJvZ+Wa20MwyzaxbVHmSme02s7nB9mxUXVczm29mi83scQsG95pZRTMbG5TPMLOkwsQmUhAt6lVjSK8kAJ7/ahlH/fVjFq9X77mIiIgcvHxXZTGzi3Mqd/dXC/G5C4BzgH/lULfE3TvlUP4MMBSYDowD+gPjgauALe7e0swuBB4EBhciNpECueeMDvRsUYerx8wmZXca/f4xhe5Jh/DK748hMaEgo8REREre0KFDARg9enTIkYjI/gqSPRwXtZ0MjATOK8yHuvsP7r6ooO3NrAFQw92neWTszUvAWUH1mcB/g/23gL6mpTKkhJzaoT5LHxhA37aHAvBN8hZa3zmeReu2syctI5+zRURK3k8//cRPP/0UdhgikoN8e8zdfVj0sZkdArxYXAEBzczsW2AbcKe7fwk0AlZFtVkVlBH8uzKINd3MUoA6wMb9L2xmQ4n0utO0aakeIi8xJC7OeH5IdwDueGc+r85YwamPTQGgesUE5v3lFOLi9F1RRERE8nYwf2/fDuQ7ndvMJpnZghy2M/M4bS3Q1N07AzcBrwYrwOSU1eybtZpXXfZC99Hu3s3du9WrVy+/WxA5YA+c3ZFxfzwu63h7ajrt7p5AekZmiFGJiIhIaVCQMebv8GuiGwd0AN7L7zx373egwbh7KpAa7M82syVEvgSsAhpHNW0MrAn2VwFNgFVmlgDUBDYf6GeLFJX2DWuQPGog7k6z4eNITc+k5YjxjBjQjv87vnnY4YmIiEiMyjcxB56M2k8Hlrt7cnEEY2b1gM3unmFmzYFWwFJ332xm283sGGAGcDnwRHDa+8AVwDQiY98/8/zWgBQpAWbG/HtOoeM9HwNw/7gfcJyhx7cIOTIRKc86dcppfQURiQUFWcf8AXe/I7+yA/pQs7OJJNb1gK3AXHc/1czOBe4l8gUgA/iLu38QnNONyNj2ykRWY7ne3d3MKgFjgM5EesovdPel+cWgdcylJK1N2U3PkZ9lHX928wk0r1ctxIhERESkpBR0HfOCJOZz3L3LfmXz3P2oQsYYKiXmUtJSdqdx1F8/zlZ2dudGPHL+UZocKiIiUoYV+gVDZnZ1sDpKGzObE7X9DPxQlMGKlAc1K1dg2cgBXNi9SVbZO9+upvkd47S0ooiUmEsvvZRLL7007DBEJAe59pgHyyLWIbJu+e1RVdvdfX0JxFas1GMuYdq2J415K7fy5zfn8cu2VACGHt+cOwa0CzkyESnr+vTpA8DkyZNDjUOkPCl0j7m7b3H3xe5+PpGx4Me6+xIg3cy0CLhIIdSoVIHjWtVj+vC+NK1dBYDRU5bSasQ4Vm7eFXJ0IiIiEoZ81zE3szuBvwB3BkWVgVeLMyiR8sLMmHLriUy55UQA0jKc4x76nD+/OY89aRm4O1pkSEREpHwoyHKJ5xFZ8WQOgLuvDl76IyJFpGmdKvx4X3/uencBb85exVvBBpAQZ8y6sx+1qiSGHKWIiIgUp4Ik5qnBsoQOYGZVijkmkXKpUoV4/n7+Udw5sD3HPfQZ2/akA5Ce6XS69xMAKleI54Uh3enUpBaVE+PDDFdESqmePXuGHYKI5KIgyyXeBjQF+gN/A64C3nb3R4s/vOKjyZ9SWjw9eTEPTViUY12fNvW4e1B7mtWtipmWXBQREYlFRbaOeXCx04BTAAMmuvv4wocYLiXmUlq4O9OXbmZW8mbGTF/O+u2pObZ7fegxHNO8TglHJyIiIvkp0sR8vwsbcIG7jz3Y4GKBEnMpzTIynSk/b+APr8xh595f10C//+wjOLdLY6Yt2cTyTTsZcmyzEKMUkVh07rnnAvD222+HHIlI+VHoxNzMqgHDgEbA+8DnwNXArcAP7j6w6MIteUrMpSx54atl3Pvh97nWvz70GC5/YSb/urQrJ7Y9tAQjE5FYo3XMRUpeodcxB8YARwE/A9cB44BLifSWl+qkXKSsubJ3Mz76Y+9c6y8cPZ296Zn87sVvOP2Jr/SmURERkRiU16osLd29I4CZPQtsBA53920lEpmIHJAODWuSPOq335lHvDOfV2asoNWh1fh5/Q7mr06h7V0TOKRKBebcdbImjYqIiMSIvHrM0/btuHsGsExJuUjpc//ZHUkeNZBPbjqBpQ8MoHvSIQBs2ZVGs+HjSM/IDDlCERERgbx7zI8ys83BvgHVg2MD3N1rF3t0IlKk4uKMN6/pRXpGJi1HRBZXajliPBcf3ZSLujdlw449dGpyCOkZmRxao1LI0YpIcejbt2/YIYhILvKa/Jnn20uCXvRSS5M/pbxzd655eTYTF/6Sa5ubTm7N0OObYwYVE/RCIxERkYNRbMsllhVKzEUiFq5J4fpXv2Xpxp15tnv6ki6c3P4wdqamU7NyBY1NFxERKSAl5vlQYi6St/SMTE5+dArLcknY2xxWneeHdKPxIVVKODIRKYzTTjsNgPHjS/27AkVKjYIm5nmNMReRciwhPo7P/9wHd+fn9Ts45dEp2eoX/bKd3g9+DsDRzWrz2v8dQ1ycetFFYt3u3bvDDkFEcqHEXETyZGa0Pqx6tqUYV2/dzcMTF/HOt6sBmLFsM83vGEfnprV48+qeJMTnteCTiIiI5CTX355mtsXMNuewbYlareWgmNnfzexHM/vOzN4xs1pRdcPNbLGZLTKzU6PKu5rZ/KDucQsGuJpZRTMbG5TPMLOkwsQmIvlrVKsyjw7uxNIHBjD19pNoWjsynOXbFVtpOWI85z87lZTdaazYtIsVm3ZpSUYREZECyKvHvG4xfu4nwHB3TzezB4HhwG1WbOmWAAAgAElEQVRm1h64EOgANAQmmVnrYAWYZ4ChwHQibyHtD4wHrgK2uHtLM7sQeBAYXIyxi0ggLs5oWKsyU249kR/XbaP/Y18C8E3yFo7668fZ2j5xUWcGHdlAk0ZFRERykWuPubtnRG9ATeCwqO2gufvH7p4eHE4HGgf7ZwKvu3uquy8DFgM9zKwBUMPdp3lktupLwFlR5/w32H8L6Gv6zS9S4trWr0HyqIEsGzmAC7o1/k399a99S7Ph4xj28uwQohORfQYNGsSgQYPCDkNEcpDvqixmNhB4lEjyvAloBPzk7m2LJACzD4Cx7v6ymT0JTHf3l4O654n0iicDo9y9X1B+HHCbuw8yswVAf3dfFdQtAY529405fNZQIr3uNG3atOvy5cuL4hZEJA/uzvzVKZzx5NfZyv9wYkt+d2wStasmqhddRETKtKJcleV+4FjgY3fvbGYnA+cWIIBJQP0cqka4+3tBmxFAOvDKvtNyaO95lOd1zm8L3UcDoyGyXGKuwYtIkTEzjmxci+RRA8nIdC4cPY1vkrfw5OeLefLzxQD0bF6H567oRtWKmo8uIiLlV0F+C6a7+wYzizMzc/dPzOz+/E7a17udGzO7AhgE9PVfu+1XAU2imjUG1gTljXMojz5nlZklEBlyU6jJqSJSPOLjjDev6UXK7jR+95+ZzFmxFYBpSzfR4S8Tefmqo2lauwpNaldWL7pIMenTpw8AkydPDjUOEfmtgiTmKWZWFfgKeMnM1gOFWmLBzPoDtwEnuPuuqKr3gVfN7B9EJn+2Ama6e4aZbTezY4AZwOXAE1HnXAFMA84DPvP8xueISKhqVq7A/649FoC0jEz+9cUSHv74Jy59fka2dh9e35sjGtUMI0QREZESV5DE/CxgD3AjkYS4JpGe7sJ4EqgIfBL0ik1392vcfaGZvQF8T2SIy3XBxFOAYcCLQGUi4873vbLseWCMmS0m0lN+YSFjE5ESVCE+jj+c1IoBHRtw0iNfZKsb9MRX2Y7n3X0KNatUKMnwRERESkxBJn8+4O535FdW2nTr1s1nzZoVdhgikgN357tVKZz51Nc51n968wm0qFethKMSKRs0lEWk5BV08mdBXs/XP4eygTmUiYgUCTPjqCaRCaOT/9yHK49tRqtDf03E+z7yBVe++A1zVmwhI1Mj10REpGzIdSiLmV0NXAO0NrM5UVXVAXU1i0iJSKpblbtPb591/MY3K7n17e/47Mf1fPbjeiCy9OLNp7TWhFGRArjgggvCDkFEcpHrUBYzOwSoA4wEbo+q2u7u60sgtmKloSwipVdaRiYPf7yIf32x9Dd1z13ejeWbd3FBt8ZUr6Tx6CIiEr6CDmXJd4x5cLEjgN7B4ZfuvrCQ8YVOiblI2bBy8y4GPP4l2/ek/6buqMY1GXXukVSqEE+zulVDiE4k9uzaFVkMrUqVKiFHIlJ+FFlibmbXAdcB7wZFZwJPufvThY4yRErMRcqeV2es4I535udY17Z+dT68vjcJ8QWZWiNSdmnyp0jJK8rE/Dugl7vvCI6rAVPd/cgiiTQkSsxFyr7XZ67g3bmrmb7013eOXdSjCXcNak+VRL1lVMonJeYiJa8oV2UxIC3qOC0oExGJaRf2aMrrQ3uybOQAuh1+CACvzVxJ+7snMnHhupCjExERyS6vVVkS3D0dGANMN7O3g6qzgf+WRHAiIkXBzHhrWC+SN+6k7z++ICPTuXrMbABu7NeKQUc2oEW9alrVRUREQpXXqixz3L1LsN8dOI5IT/kUd/+m5EIsHhrKIlJ+zUrezHnPTsuzzYCO9bn11LYkadKolDEayiJS8go6lCWvQZZZXUdBIl7qk3EREYBuSbVJHjWQ9dv3cMf/FjDph19+02bc/HWMm5/7cJf7zuxA3WoV6d6sNnWrVSzOcEWK1JAhQ8IOQURykVeP+SrgH7md6O651pUG6jEXkf2lZWSyfnsqqWkZ3P6/+cxctjn/k/Lw8PlHcV7XxkUUnYiIlFZF0WMeD1RDEz1FpJyoEB9Ho1qVAXjj6p6kZWSybONOaldNpG61imRmOlOXbCI1PYOr/pv/F/s/vzmPxIQ4zjiqYXGHLlJgGzduBKBu3bohRyIi+yvQGPOySD3mIlJU1qbs5rDqlTCDTIc4g4cmLuKZyUuy2swc0ZdDq1cKMUqRCI0xFyl5RbFconrKRUQKoEHNysTFGWZGfPDvbf3bMuWWE7Pa9Lj/U6Yt2cS3K7awNmV3iNGKiEisymsoS98Si0JEpAxqWqcKi/7Wn89/XM81L8/hon9Pz6p75pIunNaxQYjRiYhIrMm1x9zdCzfrSUREqJgQT/8jGjDppuOzlQ97ZQ4DH/+SzMy8374sIiLlR0He/CkiIoXU8tDqLBs5gORRA/nvlT0AWLhmG83vGMe3K7aEHJ2IiMSCvIayiIhIEdr3ZtETWtfju3tO4awnv2bpxp2c/fRUAK47sQVX9EqiXrWKegupFJthw4aFHYKI5CLXVVnKOq3KIiKx4KPv1nLdq3N+U37ZMYezcE0Kc1ZszSrrevghrEvZww39WnFul8akpmdQJVH9KyIisa6gq7IoMRcRiQFLNuyg7yNfFOoaHRvVpP8R9fn7xEUAPHhuRwZ3b1oU4UkZsnLlSgCaNGkSciQi5UdMJ+Zm9nfgdGAvsAT4nbtvNbMk4AdgUdB0urtfE5zTFXgRqAyMA25wdzezisBLQFdgEzDY3ZPzi0GJuYjEquSNOxnx7nwqxMfx/BXd2bgjlY07Unl79mqWbtzB5EUbDviaw09ry++ObUZigqYWlXdax1yk5MV6Yn4K8Jm7p5vZgwDufluQmH/o7kfkcM5M4AZgOpHE/HF3H29m1wJHuvs1ZnYhcLa7D84vBiXmIlKapWdkkhAfR0amk5HpvDt3NXOWb2H99tSsceoDHv8yx3OrJsbz78u70aul3vxYHikxFyl5BU3MQxmc6O4fRx1OB87Lq72ZNQBquPu04Pgl4CxgPHAmcE/Q9C3gSTMzL69jdESkXEiIj/R8x8dFXmp0QbcmXNAt+9CE5FED2bxzL/e8v5D3563JKt+5N4OLn5sBwAd/6M03yZuZvnQTg7s3oW+7w0ruJkREJJtYmDV0JTA26riZmX0LbAPudPcvgUbAqqg2q4Iygn9XAgQ98ClAHWDj/h9kZkOBoQBNm2rcpYiUfbWrJvL4RZ15/KLOAMxflcLyzTv5w6vfAnD6k19ltf34+1+y9o9tWYenL+lKjUoJWiFGRKSEFFtibmaTgPo5VI1w9/eCNiOAdOCVoG4t0NTdNwVjyt81sw5ATr8V9vWI51WXvdB9NDAaIkNZCnovIiJlRcfGNenYuCaDjmzIj+u2cfZTU9mdlsHvezfjua+WZbX7evEmjvpr5I+bzetV5dObTlCCLiJSzIotMXf3fnnVm9kVwCCg775hJ+6eCqQG+7PNbAnQmkgPeeOo0xsD+/4uuwpoAqwyswSgJqC3loqI5KNt/Rr8cF//rOMRA9uxccdeftm2hy9+2pC1usvSDTs54i8TGXJsEu9+u4bVW3dzftfG3HvmEVROjA8rfDlIN998c9ghiEguwpr82R/4B3CCu2+IKq8HbHb3DDNrDnwJdHT3zWb2DXA9MIPI5M8n3H2cmV0XtNk3+fMcd78gvxg0+VNEJH+792bQ7u4JudYf3aw2D557JE1qVyE+Tj3qIiI5ifVVWRYDFYksbwjBsohmdi5wL5HhLRnAX9z9g+Ccbvy6XOJ44PpgucRKwBigM5Ge8gvdfWl+MSgxFxEpuJvGzuXzRet56pIuVEyI494PvmfeqpRsbf55YSfOOKqhhrzEuEWLIn8JadOmTciRiJQfMZ2YxwIl5iIihbN7bwaXPT+DWcu35NpmWJ8WxJtxQ79WVIjXGuqxQMslipS8mF4uUURESr/KifG8NawXAD+s3cbNb8zj+7XbsrV5ZvISAJ78fDEAlx1zOL1a1GFm8mYm/fAL23anc2qHw5jy00buPr09fdsdSsWEX8et703PJGV3GvWqVyyhuxIRCY96zEVEpMjNW7mVRb9sJz3DueOd+UVyzb+fdyTnd9Nr5AtLPeYiJU9DWfKhxFxEpGSl7E7jjCe/olblCpzbtTGbduzF3Xn8s8Vc0fNwkjft4oufNuR7nSMa1eCda4/NGhqTkelkumuoTAEpMRcpeUrM86HEXEQk9mRmOuMXrOO41nV5b+4aLu7RlPg4Y86KLZzz9NRsba/oeTjzVqUwd+VWABrVqszfzzuS5vWqUadaohL1XCgxFyl5SszzocRcRKT0SdmdxoB/fsnqrbvzbdujWW2euaQLdapVxN1Jz1SvOsCkSZMA6Ncvz9eNiEgRUmKeDyXmIiKl1/rte+hx/6fUrZbItOF92bgjlVve/I6vFm8s0PlHNq5J75Z16Z5UmyqJ8XRPqk1csA77xh2p1K6SmHUsIlJYSszzocRcRKTs2pOWwQtfL+OhCYsO+hqXHXM4dwxoV+bebjp37lwAOnXqFHIkIuWHEvN8KDEXESl/tu7aS41KFfh5/Q5OfWwK1SslsH1Pep7n9GlTj/vP7khmpvPm7FWc0LouXQ+vzeade9m2O43RXy7l1RkrstofVqMiE244nkOqJpKZ6ezcm07FhHgSE2JjGI3GmIuUPCXm+VBiLiIi0TIzHTMwM7bvSePC0dNZuGZb/icegD5t6vHY4E7UqpJYpNc9oBiUmIuUOL1gSERE5ABEjymvXqkCH/3xOHakpnPFCzOZHbzdtGpiPDv3ZmQ77+zOjbiiVxI1K1egRqUE/j5xEa9/szKrPjEhjr3pmQBMXrSBTvd+wqv/dzT1qlVk3Px1fLV4A/WqV6RqYgI9W9ThnC6NScvI5M53FvDN8s2Mv+G4bC9dEpGySz3mIiIiB8Dd2bk3g6qJ8ZjlPEF03+/W6Pq0jEzu/eB7xkxfXqjPv7ZPC67olcRhNSpl+7ytu9KYvzqFPWkZvDt3NePmrwPgpSt7cHzremRkOss27qT/ySdRJTGBeTO/zjV+ESlaGsqSDyXmIiIShvmrUnhg3A9MW7qJo5vVpsvhhzAreTPfJG/5TdsmtSuzcnPuS0MmxBnpmQf2e3zdq7cDUP/iUdzWvy392h1Kq8OqH9hNiMgBUWKeDyXmIiISi1LTM6gQF5dtaE1aRiYJccaG7alc+8ocZi3/bRIfrWfzOjx7WVf+77+zmJm8OavcDLpUXM+Pa7ez85AW2c4ZeGQDRp7TkeoVE9STLlLElJjnQ4m5iIiUZu7OuPnr6Hr4IdSvWSn/E/Yzfv5ahr0yJ9f6t67pSbek2oUJUUQCSszzocRcRETKo6lTpwLQq1evrDJ35/15a3j440W/GToz/objaNegRonGKFLWKDHPhxJzEREpj/JbLjEtI5P3567h5jfnZSs/u3MjTu1Qn2170rj1re+yyr+4pQ+H16laXOGKlAlKzPOhxFxERMqjA1nHfPKi9Qz5zzcH9TlPX9KFk9oeSqUKWupRROuYi4iISKH0aXMoyaMGMmb6cqYt2ciP67ZzcrvD6H9EfdrWr8GDE37kxanJOZ57bTB+/ehmtXn590dTIT423nwqEsvUYy4iIlKOFMebPzMynZTdkXXUj2xUk5nJm7l6zOzftLutf1ven7eGF3/XneqVEqhcIfe14EXKkpgeymJm9wFnApnAemCIu68J6oYDVwEZwB/dfWJQ3hV4EagMjANucHc3s4rAS0BXYBMw2N2T84tBibmIiJRHxZGY52Zveiat7xyfZ5vLjjmcni3qkFSnKs3qVqVyooa+SNkT64l5DXffFuz/EWjv7teYWXvgNaAH0BCYBLR29wwzmwncAEwnkpg/7u7jzexa4Mjg/AuBs919cH4xKDEXEZHyaO7cuQB06tSpxD5zT1oGd767gJ2p6aRnOp98/0ue7e8Y0Jahx7fIs41IaRLTiXm2ACI95E3dfViwj7uPDOomAvcAycDn7t42KL8I6OPuV+9r4+7TzCwBWAfU83xuTIm5iIhIuNydhz9exFOfL8mxfs5dJ1O7amIJRyVS9GJ+8qeZ3Q9cDqQAJwbFjYj0iO+zKihLC/b3L993zkoAd083sxSgDrAxh88cCgwFaNq0aVHdioiISKkxadIkAPr16xdyJGBm3HJqW245tS0AmZnOuAVr+cOr3wLQ5b5PALjl1DYM6NiAZnWrsnnnXl6alszvj2tOtYpaw0LKlmLrMTezSUD9HKpGuPt7Ue2GA5Xc/S9m9hQwzd1fDuqeJzJsZQUw0t37BeXHAbe6++lmthA41d1XBXVLgB7uvimv+NRjLiIi5VFJjjE/WO7OLW99x1uzV+Xbtn2DGlROjKdN/epc1L0pSzbs4Maxc7Pqm9etyqlH1KdBzUo8OP5HLurRlDsHtWdPWoaWcpQSU5qGshwOfOTuR2goi4iISPEqDYl5tAWrUxj0xFfFdv0uTWvxwDkdaVtfbzeV4hPTQ1nMrJW7/xwcngH8GOy/D7xqZv8gMvmzFTAzmPy53cyOAWYQGQLzRNQ5VwDTgPOAz/JLykVERKR0OKJRTZJHDcyxbtfedE7+xxRWb92dVVY1MZ4JNx5Pw1qVGTnuBz5btJ6lG3YC8OTFnXnq8yX8sHZbVvs5K7bS/7EvAahRKYF3rzuWw2pUomowTGZtym4+mLeGPm0OpV61itSqUgF3iIvTMo9S9MJaleVtoA2R5RKXA9e4++qgbgRwJZAO3Oju44Pybvy6XOJ44PpgucRKwBigM7AZuNDdl+YXg3rMRUSkPCptPebFacP2VB7/9GfGTF9e6GvdfHJrru/bqgiikrKo1AxlCYsScxERKY+UmOds1ZZd/OPjn3hv3hoyMrPnRh0b1WT+6pQCX+vaPi34Y99W9Lh/Etv2pDOkVxJHNKrJaUfUz+qJl/JFiXk+lJiLiEh5tGjRIgDatGkTciSxKzU9g8T4uFzfSuru7Nqbweade6lUIZ6U3Wn0+8cXBb7+RT2aMvKcjkUVrpQCSszzocRcREREitqUnzYw/H/zWb11Nye1PZSrejfj51+28/DHP7EjNf037atVTGDu3SeTEB8XQrRSUpSY50OJuYiIlEcffPABAKeffnrIkZRPm3akcsaTX2ebsBrtp7+dRmKCkvSyRol5PpSYi4hIeaQx5rEjPSOTez/8npemZZ98+sRFnTn9qIYhRSXFoaCJub6SiYiIiIQgIT6Oe888guRRA1n6wICs8utf+5ZLnpvOlJ82hBidhEGJuYiIiEjI4uKMxfefxtmdGwHw9eJNXP7CTJJu/4iff9nOnrQMyusoh/JEa/aIiIiIxICE+DgeHdyJB889kv98vYyR4yPvXzz50Sk5tj+xTT2evqQrlRPjSzJMKUbqMRcRERGJIYkJcVx9QguSRw3kP0O659ru80UbaHf3BJJu/4hZyZtJ3riTzTv3lmCkUtQ0+VNERKQcWblyJQBNmjQJORI5WHvSMhg6Zjbbdqcxd+XWXNsd1aQWz1/RjR170lm6cQf1a1SmfcMaJRip7KNVWfKhxFxERETKgjdmreTWt74rUNtDqlRg6u19NfylhCkxz4cScxERKY/Gjh0LwODBg0OORIpDZqaT6c7clVu5/rVvWZuyh5qVK5CyO+03bUee05GzOzeiUgUl6cVNiXk+lJiLiEh5pHXMy6/0jEye+Gwx//z05xzrG9SsxFvDetGoVuUSjqzsK2hirlVZRERERMqBhPg4/nRya/50cmvmrNjCQxN+ZPrSzVn1a1P2cOyoz6hdNTFrEulb1/SkW1LtrDY7U9NZvz2VhrUqUTFBPe1FTYm5iIiISDnTpekhvD60JwCL1m1n6pKNjJu/lm+St2Rb2eW8Z6cB0KtFHaYu2ZTtGncPas/vjk3CzEou8DJOQ1lERETKEQ1lkYKasXQTg0dPz7fdoCMbsGbrbuas+HWFmK6HH8LYoceQEK+VuUFjzPOlxFxERMojJeZyoLbs3MtTny/muNb1OL5VXcyMlZt3MeQ/M1myYWee57Y8tBqH167Cpz+u5/e9m3FYjUqc2LYeLQ+tXkLRxwYl5vlQYi4iIuXRxo0bAahbt27IkUhZsDM1nee+XAbApcc0ZevuNJrXrcqwl+cwYeG6PM+95OimjBjYjiqJZX9ktRLzfCgxFxERESk+O1LTmblsEze/MY+qFRNYvy2Vdg1rMG+/lyL998oeVE2Mp+vhh5TZ8epKzPOhxFxERMqjF198EYAhQ4aEGoeUXxmZTsruNIa9PJsZyzbn275DwxrcObA9PVvUKYHoikdMJ+Zmdh9wJpAJrAeGuPsaM0sCfgAWBU2nu/s1wTldgReBysA44AZ3dzOrCLwEdAU2AYPdPTm/GJSYi4hIeaQx5hJLBv9rWoGS87zEGWQ6NKxZiZeuOpqWh1b7TZv0jMxQJ6LG+jrmf3f3uwDM7I/A3cA1Qd0Sd++UwznPAEOB6UQS8/7AeOAqYIu7tzSzC4EHAb3OTERERCTGjb26Z47l7s67c1ezeP0O5q1M4avFG3O9RmbQx7wmZQ/9/vFFVvmN/VqxY086z30VGQN/W/+2DOvTouiCLwahJObuvi3qsCqQZ7e9mTUAarj7tOD4JeAsIon5mcA9QdO3gCfNzLy8jtERERERKeXMjLM7N85Wtjc9k9Vbd5NUpwoQGcNeNTGBpRt3UK1iBaYt3cifxs7Lav/YpOxvOP37xB85r2tj6lWvWPw3cJBCmwZrZvcDlwMpwIlRVc3M7FtgG3Cnu38JNAJWRbVZFZQR/LsSwN3TzSwFqAP85quVmQ0l0utO06ZNi/R+RERERKT4JCbE0axu1azj6pUqAGQtvXh258ZZyXzK7jT+NHYuW3ft5dnLulKtYgLLN+2K6aQcijExN7NJQP0cqka4+3vuPgIYYWbDgT8AfwHWAk3dfVMwpvxdM+sA5DRFd1+PeF512QvdRwOjITLG/IBuSERERERKhZqVK/DCkO7Zyto1qBFSNAVXbIm5u/crYNNXgY+Av7h7KpAanD/bzJYArYn0kEf/PaMxsCbYXwU0AVaZWQJQEyjcLAIREZEyaty4cWGHICK5CGV6qpm1ijo8A/gxKK9nZvHBfnOgFbDU3dcC283sGIsscHk58F5w/vvAFcH+ecBnGl8uIiKSsypVqlClSpWwwxCRHIQ1xnyUmbUhslzicn5dkeV44F4zSwcygGvcfV/v9zB+XS5xfLABPA+MMbPFRHrKLyyROxARESmFnn76aQCuvfbakCMRkf3pBUMiIiLliNYxFyl5BV3HPLyV1kVEREREJIsScxERERGRGKDEXEREREQkBigxFxERERGJAeV28qeZbSCyIkwY6pLDm0nlgOgZFp6eYeHpGRaenmHh6RkWDT3HwtMzzN3h7l4vv0blNjEPk5nNKsjMXMmdnmHh6RkWnp5h4ekZFp6eYdHQcyw8PcPC01AWEREREZEYoMRcRERERCQGKDEPx+iwAygD9AwLT8+w8PQMC0/PsPD0DIuGnmPh6RkWksaYi4iIiIjEAPWYi4iIiIjEACXmIiIiIiIxQIl5CTKz/ma2yMwWm9ntYccTS8ysiZl9bmY/mNlCM7shKK9tZp+Y2c/Bv4dEnTM8eJaLzOzUqPKuZjY/qHvczCyMewqLmcWb2bdm9mFwrGd4AMyslpm9ZWY/Bv899tQzPDBm9qfgf8cLzOw1M6ukZ5g/M3vBzNab2YKosiJ7bmZW0czGBuUzzCypJO+vJOTyDP8e/O/5OzN7x8xqRdXpGe4np2cYVfdnM3MzqxtVpmdYlNxdWwlsQDywBGgOJALzgPZhxxUrG//f3v3HWl3XcRx/voIUkPwBjlKwLqbTbCPv1TFNxlg4luK4rdywZNCsNldba80Mo0zWH43WwraWsOGcJEKlDF2uZAOXqwH35gWBwJTiilcwdKWYMuXHuz8+nwvfe3YunIOHe77c+3ps353veX9/3M/3tcs9H77fz/l+4SKgLc9/BHgRuAr4GTA/1+cDi/L8VTnDs4GJOdtheVkHcD0g4I/ATc0+vgHO8rvAo8Af8ntnWF9+DwNfz/NnAec7w7ryGw/sBkbm978DvuoMa8puKtAGbC/UGpYb8E1gSZ6/Dfhts495gDKcAQzP84ucYf0Z5volwNOkhzNe6AxPz+Qz5gNnMrArIv4VEe8Dq4D2JrepNCJiX0R05fm3gZ2kD/h2UkeJ/PqFPN8OrIqI9yJiN7ALmCzpIuDciNgQ6V/98sI2g56kCcBMYFmh7AxrJOlc0ofSgwAR8X5EvIkzrNdwYKSk4cAoYC/O8KQi4lngPxXlRuZW3NdjwPTBdhWiWoYRsTYiDue3G4EJed4ZVtHP7yHAYuBuoHjXEGfYYO6YD5zxwCuF9z25ZhXyZa1WYBPw0YjYB6nzDozLq/WX5/g8X1kfKu4n/eE8Wqg5w9pdCrwOPKQ0HGiZpHNwhjWLiFeBnwN7gH3AWxGxFmd4qhqZ27Ftckf1LWDsaWt5Od1BOnsLzrBmkmYBr0bE8xWLnGGDuWM+cKr9b9D3qqwgaTTwOPCdiDhwolWr1OIE9UFP0i3A/oh4rtZNqtSGdIakM71twAMR0Qq8Qxo+0B9nWCGPgW4nXda+GDhH0pwTbVKlNqQzrNGp5DakM5W0ADgMrOgtVVnNGVaQNApYANxbbXGVmjP8ANwxHzg9pPFZvSaQLu9aJunDpE75iohYncv/zpfEyK/7c72/PHs4fpmyWB8KbgBmSeomDZX6nKRHcIb16AF6ImJTfv8YqaPuDGt3I7A7Il6PiEPAauCzOMNT1cjcjm2ThxmdR/UhC4OOpHnALcDteWgFOMNafZL0H+3n8+fLBKBL0sdwhg3njvnA6QQulzRR0lmkLzw82eQ2lUYeX/YgsDMiflFY9CQwL8/PA54o1G/L3+6eCFwOdORLvW9Lui7vc25hm0EtIu6JiAkR0UL6/VofEXNwhuDHzRYAAARjSURBVDWLiNeAVyRdkUvTgR04w3rsAa6TNCof+3TSd0ac4alpZG7Ffd1K+hsx6M9USvo88H1gVkS8W1jkDGsQEdsiYlxEtOTPlx7SzRpewxk2XrO+dToUJ+Bm0t1G/gksaHZ7yjQBU0iXsrYCW/J0M2nc2Trgpfw6prDNgpzlPyjcrQG4Ftiel/2K/ITboTQB0zh+VxZnWF92VwN/y7+La4ALnGHdGS4EXsjH/xvSHRuc4clzW0kal3+I1Pn5WiNzA0YAvyd9Qa8DuLTZxzxAGe4ijWnu/WxZ4gzry7BieTf5rizOsPFTb0hmZmZmZtZEHspiZmZmZlYC7pibmZmZmZWAO+ZmZmZmZiXgjrmZmZmZWQm4Y25mZmZmVgLumJuZlYikI5K2FKYTPXkUSXdKmtuAn9st6cIPup8GtOM+SXc1ux1mZs0wvNkNMDOzPg5GxNW1rhwRS05nY84k+UEmioijzW6Lmdmp8BlzM7MzQD6jvUhSR54uy/VjZ5glfVvSDklbJa3KtTGS1uTaRkmTcn2spLWSNktaCqjws+bkn7FF0lJJw/ppz0JJXZK2Sbqysj35/XZJLXl6QdKyXFsh6UZJf5X0kqTJhd1/RtL6XP9GYV/fk9SZj2VhrrVI2inp10AXfR8PbmZ2RnHH3MysXEZWDGWZXVh2ICImk56id3+VbecDrRExCbgz1xYCm3PtB8DyXP8x8JeIaCU9IvvjAJI+BcwGbshn7o8At/fT1jciog14AKhl+MllwC+BScCVwFdIT/29K7et1yRgJnA9cK+kiyXNID3uezLp6azXSJqa178CWB4RrRHxcg3tMDMrJQ9lMTMrlxMNZVlZeF1cZflWYIWkNcCaXJsCfAkgItbnM+XnAVOBL+b6U5L+m9efDlwDdKaRIYwE9vfTntX59bnefZ3E7ojYBiDp78C6iAhJ24CWwnpPRMRB4KCkZ0id8SnADGBzXmc0qaO+B3g5IjbW8PPNzErNHXMzszNH9DPfayapwz0L+JGkT1MYolJl22r7EPBwRNxTQ3vey69HOP55cpi+V2NHVFkf4Gjh/VH6fh5Vtityu34aEUv7NFZqAd6poa1mZqXnoSxmZmeO2YXXDcUFkj4EXBIRzwB3A+eTzio/Sx6KImkaafjJgYr6TcAFeVfrgFsljcvLxkj6RB1t7Aba8rZtwMS6jjBplzRC0lhgGtAJPA3cIWl03vf43jaamQ0WPmNuZlYuIyVtKbz/U0T03jLxbEmbSCdVvlyx3TDgkTxMRcDiiHhT0n3AQ5K2Au8C8/L6C4GVkrqAP5OGhBAROyT9EFibO/uHgG8BtY7dfhyYm4+hE3ix1gMv6ACeIo17/0lE7AX25vHvG/IQm/8Bc0hn683MBgVFVLuSaWZmZSKpG7g2It5odlvMzOz08FAWMzMzM7MS8BlzMzMzM7MS8BlzMzMzM7MScMfczMzMzKwE3DE3MzMzMysBd8zNzMzMzErAHXMzMzMzsxL4P7Imqo//oGisAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...completed in 4.3 seconds @ 3461.8 games per second\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Validation metrics\n",
      "---------------------------\n",
      "After final episode, mean reward of -0.1472 over last 2500 episodes --> success rate: 0.40676384002297694\n",
      "After episode 10307, mean reward of -0.0764 over last 2500 episodes --> success rate: 0.3933284838407981\n"
     ]
    }
   ],
   "source": [
    "# just one set of parameters to go through at this stage\n",
    "grid_size = len(grid)\n",
    "all_eval_metrics = train_agent(0, grid[0], False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Optimization : training with grid search\n",
    "\n",
    "Now that we know the Q-learning process is working, we can expand the grid search and simply-reuse our earlier functions to optimize learning. We will keep the grid fairly small so that this notebook does not get too large. (The first time I performed the grid search was with a much larger grid in Spyder, which I prefer for larger tasks.)\n",
    "\n",
    "We will alo raise the number of episodes to train and evaluate over, so that we can get more robust estimations of performance. If we were carrying out analysis in Spyder we should raise the numbers even higher.\n",
    "\n",
    "At this point it is also useful to reduce verbosity to just validation metrics. We will split this into two chunks to reduce risk of any errors / crashes, with the first chunk using only the Boltzmann policy and the second only an e-greedy policy.\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\" align=\"center\"><b>Warning:</b> The next two blocks could take up to an hour to complete and may be difficult to interrupt! </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of episodes to train agent over\n",
    "NUM_EPISODES_TRAIN = 125000\n",
    "\n",
    "# evaluate agent with mean rewards over last (N) episodes\n",
    "EVAL_LAST_N_EPS = 20000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Now training agent 1/8\n",
      "DblQ: 0.00 | LR: 0.010 | g: 0.400 | pol: b | pol_param: 1.00000\n"
     ]
    }
   ],
   "source": [
    "# reduce verbosity level - feedback validation metrics only\n",
    "VERBOSE = 0\n",
    "\n",
    "# Create a grid of hyper parameters to search over\n",
    "grid = ParameterGrid({\"dbl_Q\" : [0, 1],                 # 1 to use Double Q learning\n",
    "                          \"lr\": [0.01, 0.001],       # learning rate\n",
    "                          \"y\": [0.4, 0.8],              # gamma\n",
    "                          \"policy\": [\"b\"],              # \"e\" for e-greedy, \"b\" for boltzmann\n",
    "                          \"policy_param\":  [1],         # tau (inverse temperature)\n",
    "                          \"num_episodes\": [NUM_EPISODES_TRAIN],\n",
    "                          \"cb_over_num_eps\": [EVAL_LAST_N_EPS],\n",
    "                          \"verbose\": [VERBOSE]})\n",
    "grid_size = len(grid)\n",
    "\n",
    "# create a new array to store evaluation metrics for all agents\n",
    "# we pass this to the function so that it can append a new row\n",
    "# on each iteration\n",
    "all_eval_metrics = []\n",
    "for p_idx, params in enumerate(grid):\n",
    "    all_eval_metrics = train_agent(p_idx, params, True, all_eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a grid of hyper parameters to search over\n",
    "grid = ParameterGrid({\"dbl_Q\" : [0, 1],                 # 1 to use Double Q learning\n",
    "                          \"lr\": [0.01, 0.001],       # learning rate\n",
    "                          \"y\": [0.3, 0.8],              # gamma\n",
    "                          \"policy\": [\"e\"],              # \"e\" for e-greedy, \"b\" for boltzmann ## MODIFIED ##\n",
    "                          \"policy_param\":  [0.6],       # epsilon ## MODIFIED ##\n",
    "                          \"num_episodes\": [NUM_EPISODES_TRAIN],\n",
    "                          \"cb_over_num_eps\": [EVAL_LAST_N_EPS],\n",
    "                          \"verbose\": [VERBOSE]})\n",
    "grid_size = len(grid)\n",
    "\n",
    "# pass the same evaluation metric array\n",
    "for p_idx, params in enumerate(grid):\n",
    "    all_eval_metrics = train_agent(p_idx, params, True, all_eval_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now summarise the results for all our trained agents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define column names and form a dataframe of results\n",
    "# we order by the evaluation metric MeanR_lastN and show top 5\n",
    "col_names = ['agent_filepath', 'DoubleQ', 'lr', 'y', 'policy', 'pol_param', 'num_episodes',\n",
    "             'cb_over_num_episodes', 'cb_creation_idx', 'meanR_lastN', 'success_rate_lastN']\n",
    "eval_df = pd.DataFrame(data=np.array(all_eval_metrics), columns=col_names) \\\n",
    "            .sort_values(by='meanR_lastN', ascending=True) \\\n",
    "            .reset_index().drop('index', 1)\n",
    "eval_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Comparison against human strategy\n",
    "\n",
    "Unsurprisingly, none of our agents discovered a way to make money out of Blackjack in the long-run. We know this since their average reward per game maxes out around -0.04. In other words, they will lose (or sometimes draw) about X% of the time. Of course, winning Y% of the time is much better than when our agents first started!\n",
    "\n",
    "An interesting comparison we can make is whether this Y% success rate is better than that achieved by humans. This is a little difficult since our version of Blackjack is non-standard and excludes the \"split\" option, which can be helpful in hedging bets. <a href=\"https://www.blackjackapprenticeship.com/blackjack-strategy-charts/\" target=\"_blank\">BlackjackApprenticeship.com</a> offers advice for non-splitting scenarios, which appears to be a sensible set of instructions we can use in our version of the game.\n",
    "\n",
    "We have encoded the advice into matrices held in csv format, visualised below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def action_dict(a, short=False):\n",
    "    \"\"\" Return the initial letter or name of action given an action index\"\"\"\n",
    "    if short:\n",
    "        lookup = {0: \"S\", 1: \"H\", 2: \"D\", 3: \"U\", 4: \"I\"}\n",
    "    else:\n",
    "        lookup = {0: \"Stick\", 1: \"Hit\", 2: \"Double\", 3: \"Surrender\", 4: \"Invest\"}\n",
    "    return lookup[a]\n",
    "\n",
    "def make_adviceChart(Q_in, add_title='', smeChart=False):\n",
    "    \"\"\" Find the argmax for each value of Q matrix along the action dimension\n",
    "        Convert each to the name label of the action & color code \n",
    "        This acts as an easy 'advice chart' to support understanding \"\"\"\n",
    "    # take top-expectation action per state\n",
    "    if not(smeChart):\n",
    "        Qa_max = np.argmax(Q, axis=-1)\n",
    "        \n",
    "    # split into no usable ace / useable ace states\n",
    "    plt.figure()\n",
    "    f, axes = plt.subplots(1,2, sharex=False, sharey=False,\n",
    "                                      figsize=(12,6))\n",
    "    plt.title('Advised action chart per state')\n",
    "    j_labels = ['No usable Ace', 'Usable Ace']\n",
    "    for j in [0,1]:\n",
    "        # load human advice charts rather than Q matrix if requested\n",
    "        if ((smeChart) & (j==0)):\n",
    "            Qa_max = np.array(pd.read_csv('additional_analysis/sme_advice_noUseableAce.csv'))\n",
    "            Qa_maxJ = Qa_max[4:,:]\n",
    "        elif ((smeChart) & (j==1)):\n",
    "            Qa_max = np.array(pd.read_csv('additional_analysis/sme_advice_UseableAce.csv'))\n",
    "            Qa_maxJ = Qa_max[4:,:]\n",
    "        else:\n",
    "            Qa_maxJ = Qa_max[4:22,1:,j]\n",
    "            \n",
    "        # convert action IDs to labels\n",
    "        Qa_maxJ_label = np.chararray((Qa_maxJ.shape[0], Qa_maxJ.shape[1]), unicode=True)\n",
    "        for x in np.arange(0, Qa_maxJ.shape[0]):\n",
    "            for y in np.arange(0, Qa_maxJ.shape[1]):\n",
    "                # for invalid values label as \"-\"\n",
    "                if ((j==1) & (x<=7)):\n",
    "                    Qa_maxJ_label[x,y] = \"-\"                                        \n",
    "                else:\n",
    "                    Qa_maxJ_label[x,y] = action_dict(Qa_maxJ[x,y], short=True)\n",
    "\n",
    "        # obtain the relevant Q values - hiding non-used states (4- & 22+ for player / 0 for dealer)\n",
    "        g = sns.heatmap(Qa_maxJ, cmap='Reds', annot=Qa_maxJ_label, fmt ='',\n",
    "                        cbar=False, ax=axes[j], vmin=0, vmax=5)\n",
    "        g.set_title(\"{}{}\".format(j_labels[j], add_title))\n",
    "        g.set_xlabel('Dealer initial card')\n",
    "        # set agent hand value range of 4-21 inclusive, dealer 2-11 inclusive\n",
    "        g.set_yticklabels(np.arange(4,22), rotation=0)\n",
    "        g.set_xticklabels(np.arange(1,11), rotation=0)  # where Ace = 1 for now\n",
    "        # only show y label on first plot\n",
    "        if j == 0:\n",
    "            g.set_ylabel('Agent hand value')\n",
    "\n",
    "make_adviceChart(Q_in = None, add_title='\\nExpert advice', smeChart=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have visualised the human strategy, we will form a 3D matrix aligned to the format of the Q-matrices our agents were using. Rather than storing estimated values, however, it will simply store the ID of the action to take for any given state. This will help us insert the static strategy into the environment with minimal code changes required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load files and stack into a 3D array\n",
    "Qh_no_ace = np.array(pd.read_csv('additional_analysis/sme_advice_noUseableAce.csv'))\n",
    "Qh_ace = np.array(pd.read_csv('additional_analysis/sme_advice_UseableAce.csv'))\n",
    "Qh = np.dstack([Qh_no_ace, Qh_ace])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can perform 50,000 simulations and calculate the average reward and success rate for this human strategy. Since the strategy is fixed and no learning is occurring, we do not need to play the full 250,000 games that the agents played. We must however ensure the strategy is evaluated over the same number of simulations: 50,000.\n",
    "\n",
    "To get a better estimate of these evaluation metrics, we will perform the 50,000 simulations 50 times and take the average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_simulation_rounds = 50\n",
    "list_meanR = []\n",
    "list_success = []\n",
    "for t in np.arange(0, num_simulation_rounds):\n",
    "    #create list to contain total rewards and steps per episode\n",
    "    rList = []\n",
    "    for i in range(NUM_EPISODES_TRAIN): #EVAL_LAST_N_EPS):\n",
    "        #Reset environment and get first new observation\n",
    "        s = env.reset()\n",
    "        rAll = 0\n",
    "        d = False\n",
    "        j = 0\n",
    "\n",
    "        # game will not exceed 20 moves, limit while loop out of caution\n",
    "        while j < 20:\n",
    "            j+=1\n",
    "\n",
    "            # choose action per fixed strategy\n",
    "            # need to adjust the indices slightly for true alignment\n",
    "            a = Qh[s[0], s[1]-1, s[2]]\n",
    "\n",
    "            #Get new state and reward from environment\n",
    "            player_hand_old = env.player.copy()\n",
    "            s1,r,d,_ = env.step(a)\n",
    "\n",
    "            # update rewards and state\n",
    "            rAll += r\n",
    "            s = s1\n",
    "\n",
    "            # end game when a winner/loser found\n",
    "            if d == True:            \n",
    "                # For each of the final 5 episodes, show the game for inspection\n",
    "                if ((i >= (NUM_EPISODES_TRAIN-5)) & (t==0)):\n",
    "                    show_ep(env.player, env.dealer, r, i)\n",
    "                break\n",
    "\n",
    "        # append reward to list\n",
    "        rList.append(rAll)\n",
    "\n",
    "    # show overall success history of fixed strategy for first simulation round\n",
    "    if t == 0:\n",
    "        plt.figure(figsize=(12,4))\n",
    "        plt.plot(np.cumsum(rList))\n",
    "        plt.title('Performance vs. episodes (Human strategy - first simulation round)')\n",
    "        plt.ylabel('Total Returns')\n",
    "        plt.xlabel('Episode number')\n",
    "        plt.show()\n",
    "\n",
    "    meanR = meanR_lastN(rList, EVAL_LAST_N_EPS)\n",
    "    ts_success, mean_success_rate = calc_success_rate(rList, produce_ts=False)\n",
    "    \n",
    "    if t % 10 == 0:\n",
    "        print(\"Round %i. Mean rewards of %.5f over %i games --> success rate: %.5f\" % (t, meanR,\n",
    "                                                                          EVAL_LAST_N_EPS,\n",
    "                                                                          mean_success_rate))\n",
    "    # add new metrics to running lists\n",
    "    list_meanR.append(meanR)\n",
    "    list_success.append(mean_success_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now show averages of evaluation metrics after all the simulations\n",
    "print(\"FINAL EVALUATION METRICS FOR HUMAN STRATEGY:\")\n",
    "print(\"Mean of mean rewards: %.5f\" % np.array(list_meanR).mean())\n",
    "print(\"Mean of success rates: %.5f\" % np.array(list_success).mean())\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1,2)\n",
    "ax1.hist(np.array(list_meanR))\n",
    "ax2.hist(np.array(list_success))\n",
    "#ax2.set_xlim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gym_env)",
   "language": "python",
   "name": "gym_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
